{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "accepted_answers = json.load(open('ten_thousand_questions/questions_with_bodies.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accepted_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "from stackapi import StackAPI\n",
    "\n",
    "SITE = StackAPI('stackoverflow')\n",
    "aids = [i['accepted_answer_id'] for i in accepted_answers]\n",
    "print(len(aids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n"
     ]
    },
    {
     "ename": "StackAPIError",
     "evalue": "('https://api.stackexchange.com/2.2/answers/67583894;67583898;67573737;67583261;67582690;67581909;56764078;67581129;67580063;67579980;67579264;67578947;67578588;67577790;67576686;67576263;33611953;67575748;67575208;67575039;67574914;37926646;67574569;67574296;67573939;67573684;67551550;67573156;67573150;67573033;67572333;37256579;56033064;67570968;67570701;67569746;67568563;67567713;67348089;67567190;67565540;67566662;58647642;67566010;67562321;41449714;67564927;67564885;67564249;67564528;67563515;67561636;67563278;67562403;67560880;67559743;67560450;67556995;67560013;67559954;52300848;67558577;67555587;67557843;67557735;67557145;67556420;67556553;67556488;67556195;45273750;67555366;67555501;67515824;67552826;67552927;67552701;67552194;67551669;32470490;67551396;67549898;67551152;67549232;67549481;67549287;32444187;67549122;67548788;67547650;67547147;67547010;67546281;67544276;46429034;67543517;67542809;67540941;67540709;67538981/?pagesize=100&page=1&filter=withbody&site=stackoverflow', 502, 'throttle_violation', 'too many requests from this IP, more requests available in 8264 seconds')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStackAPIError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-464a918fb16a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;34m'answers/{ids}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'withbody'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         )['items']\n\u001b[1;32m     10\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda2/envs/fairseq-wasi/lib/python3.6/site-packages/stackapi/stackapi.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, endpoint, page, key, filter, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"error_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"error_message\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mStackAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_previous_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0;32mpass\u001b[0m  \u001b[0;31m# This means there is no error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStackAPIError\u001b[0m: ('https://api.stackexchange.com/2.2/answers/67583894;67583898;67573737;67583261;67582690;67581909;56764078;67581129;67580063;67579980;67579264;67578947;67578588;67577790;67576686;67576263;33611953;67575748;67575208;67575039;67574914;37926646;67574569;67574296;67573939;67573684;67551550;67573156;67573150;67573033;67572333;37256579;56033064;67570968;67570701;67569746;67568563;67567713;67348089;67567190;67565540;67566662;58647642;67566010;67562321;41449714;67564927;67564885;67564249;67564528;67563515;67561636;67563278;67562403;67560880;67559743;67560450;67556995;67560013;67559954;52300848;67558577;67555587;67557843;67557735;67557145;67556420;67556553;67556488;67556195;45273750;67555366;67555501;67515824;67552826;67552927;67552701;67552194;67551669;32470490;67551396;67549898;67551152;67549232;67549481;67549287;32444187;67549122;67548788;67547650;67547147;67547010;67546281;67544276;46429034;67543517;67542809;67540941;67540709;67538981/?pagesize=100&page=1&filter=withbody&site=stackoverflow', 502, 'throttle_violation', 'too many requests from this IP, more requests available in 8264 seconds')"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "\n",
    "for idx in range(100):\n",
    "    answers.extend(\n",
    "        SITE.fetch(\n",
    "            'answers/{ids}', \n",
    "            ids=aids[idx*100:(idx+1)*100], \n",
    "            filter='withbody'\n",
    "        )['items']\n",
    "    )\n",
    "    print(len(answers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "print(len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answers = answers['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "final_answers.extend(SITE.fetch('answers/{ids}', ids=aids[100:200], filter='withbody')['items'])\n",
    "print(len(final_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "final_answers.extend(SITE.fetch('answers/{ids}', ids=aids[200:300], filter='withbody')['items'])\n",
    "print(len(final_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_answer = {\n",
    "    answer['answer_id']: answer for answer in final_answers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(accepted_answers)):\n",
    "    accepted_answers[idx]['answer_body'] = id_to_answer[accepted_answers[idx]['accepted_answer_id']]['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "qids = [i['question_id'] for i in accepted_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "question_items = SITE.fetch('questions/{ids}', ids=qids[:100], filter='withbody')['items']\n",
    "question_items.extend(SITE.fetch('questions/{ids}', ids=qids[100:200], filter='withbody')['items'])\n",
    "question_items.extend(SITE.fetch('questions/{ids}', ids=qids[200:300], filter='withbody')['items'])\n",
    "print(len(question_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_body = {\n",
    "    q['question_id']: q['body'] for q in question_items\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(accepted_answers)):\n",
    "    accepted_answers[idx]['question_body'] = id_to_body[accepted_answers[idx]['question_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Mining Pandas APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "urls = json.load(open(\"pandas_apis.json\"))\n",
    "data_frame_url = urls[\"df\"]\n",
    "\n",
    "def get_api_list(_url):\n",
    "    page = requests.get(_url)\n",
    "    soup = bs(page.content, 'html.parser')\n",
    "    codes = soup.find_all(\"code\", {\"class\": \"xref py py-obj docutils literal notranslate\"})\n",
    "    apis = []\n",
    "    for code in codes:\n",
    "        api_name = code.find(\"span\").text\n",
    "        if \".\" in api_name:\n",
    "            name = api_name[api_name.index(\".\") + 1:]\n",
    "            apis.append(name)\n",
    "            pass\n",
    "        else:\n",
    "            apis.append(api_name)\n",
    "        pass\n",
    "    return apis\n",
    "\n",
    "data_frame_apis = get_api_list(data_frame_url)\n",
    "# print(data_frame_apis)\n",
    "\n",
    "list_of_apis = []\n",
    "complete_api_sets = []\n",
    "\n",
    "for key in urls:\n",
    "    api_from_url = get_api_list(urls[key])\n",
    "    list_of_apis.append({\n",
    "        \"url_key\": key,\n",
    "        \"url\": urls[key],\n",
    "        \"apis\": api_from_url\n",
    "    })\n",
    "    complete_api_sets.extend(api_from_url)\n",
    "    pass\n",
    "\n",
    "# print(\"Dataframe APIs only\")\n",
    "# print(data_frame_apis)\n",
    "# print(\"=\" * 100)\n",
    "# print(\"Pandas APIS\")\n",
    "complete_api_sets = list(set(complete_api_sets))\n",
    "# print(complete_api_sets)\n",
    "# print(\"=\" * 100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello() False\n",
      "concat(dsaf) True\n",
      "index() True\n",
      "dasfasd False\n"
     ]
    }
   ],
   "source": [
    "# print(data_frame_apis)\n",
    "\n",
    "def dataframe_api_exists(line):\n",
    "    for api in data_frame_apis:\n",
    "        if api in line:\n",
    "            return True\n",
    "        pass\n",
    "    return  False\n",
    "\n",
    "def api_exists(line):\n",
    "    for api in complete_api_sets:\n",
    "        if api in line:\n",
    "            return True\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "\n",
    "lines = [\"hello()\", \"concat(dsaf)\", \"index()\", \"dasfasd\"]\n",
    "for l in lines:\n",
    "    print(l, dataframe_api_exists(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import keyword\n",
    "\n",
    "keywords = keyword.kwlist\n",
    "\n",
    "def keyword_exists(line):\n",
    "    for kw in keywords:\n",
    "        if (kw + \" \") in line or (\" \" + kw) in line:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def min_word_filter(texts, min_word=5):\n",
    "    filtered_texts = []\n",
    "    for t in texts:\n",
    "        if len(t.split()) >= min_word:\n",
    "            filtered_texts.append(t)\n",
    "            pass\n",
    "        pass\n",
    "    return filtered_texts\n",
    "\n",
    "def extract_code(text, filters):\n",
    "    soup = bs(text)\n",
    "    all_code = [code.text for code in soup.find_all('code')]\n",
    "    for f in filters:\n",
    "        all_code = f(all_code)\n",
    "    return all_code\n",
    "    pass\n",
    "\n",
    "def data_frame_exists(code):\n",
    "    lines = [l.strip() for l in code.split(\"\\n\")]\n",
    "    data_frame_re = \"[0-9]+[, \\t]+[.]*\"\n",
    "    matches = []\n",
    "    for l in lines:\n",
    "        if len(re.findall(data_frame_re, l)) > 0 \\\n",
    "            and not keyword_exists(l) \\\n",
    "            and not dataframe_api_exists(l) \\\n",
    "            and not api_exists(l):\n",
    "            matches.append(True)\n",
    "        else:\n",
    "            matches.append(False)\n",
    "    return any(matches)\n",
    "\n",
    "def code_exists(code):\n",
    "    lines = [l.strip() for l in code.split(\"\\n\")]\n",
    "    matches = []\n",
    "    for l in lines:\n",
    "        if dataframe_api_exists(l) or keyword_exists(l) or api_exists(l):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def print_formatted_code(code):\n",
    "    lines = code.split('\\n')\n",
    "    lines = ['\\t\\t' + l for l in  lines]\n",
    "    print('\\n'.join(lines))\n",
    "    \n",
    "def extract_description(html):\n",
    "    soup = bs(html)\n",
    "    [code.extract() for code in soup.find_all('code')]\n",
    "    text = re.sub(\"[ \\n\\t]+\", \" \", soup.text)\n",
    "    return text\n",
    "    pass\n",
    "    \n",
    "taken_answers = []\n",
    "\n",
    "for a in accepted_answers:\n",
    "    title = a['title']\n",
    "    code_from_body = extract_code(a['question_body'], filters=[min_word_filter])\n",
    "    code_from_answer = extract_code(a['answer_body'], filters=[min_word_filter])\n",
    "    data_frames = []\n",
    "    for cid, c in enumerate(code_from_body):\n",
    "        is_df = data_frame_exists(c)\n",
    "        is_code = code_exists(c)\n",
    "        if is_df and not is_code:\n",
    "            data_frames.append(c)\n",
    "        \n",
    "    taken_code = []\n",
    "    for cid, c in enumerate(code_from_answer):\n",
    "        is_df = data_frame_exists(c)\n",
    "        is_pandas_code = api_exists(c)\n",
    "        if is_pandas_code and not is_df:\n",
    "            taken_code.append(c)\n",
    "    if len(data_frames) == 2 and len(taken_code) > 0:\n",
    "        a[\"formatted_input\"] = {\n",
    "            \"qid\": a['question_id'],\n",
    "            'link': a['link'],\n",
    "            \"question\": {\n",
    "                \"title\": a[\"title\"],\n",
    "                \"ques_desc\" : extract_description(a['question_body'])\n",
    "            },\n",
    "            \"io\": data_frames,\n",
    "            \"answer\" : {\n",
    "                \"ans_desc\" : extract_description(a['answer_body']),\n",
    "                \"code\": taken_code\n",
    "            }\n",
    "        }\n",
    "        taken_answers.append(a)\n",
    "\n",
    "print(len(taken_answers))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"qid\": 68243146\n",
      "\"link\": https://stackoverflow.com/questions/68243146/replace-zero-with-value-of-an-other-column-using-pandas\n",
      "\"question\": {\n",
      "\t\"title\": replace zero with value of an other column using pandas\n",
      "\t\"desc\": I have a dataframe df1: I want to replace 0 in the id column with value from ref column of the same row So it will become: \n",
      "}\n",
      "\"io\": {\n",
      "\t\"Frame-1\": \n",
      "\t\t    ref   Name   id  Score\n",
      "\t\t  8400   John    0     12\n",
      "\t\t  3840  Peter  414      0\n",
      "\t\t  7400  David  612     64\n",
      "\t\t  5200  Karen    0      0\n",
      "\t\t\n",
      "\t\"Frame-2\":\n",
      "\t\t   ref    Name   id   Score\n",
      "\t\t  8400   John  8400     12\n",
      "\t\t  3840  Peter  414      0\n",
      "\t\t  7400  David  612     64\n",
      "\t\t  5200  Karen 5200      0\n",
      "\t\t\n",
      "}\n",
      "\"answer\": {\n",
      "\t\"desc\": %s via : OR via numpy's : \n",
      "\t\"code-snippets\": [\n",
      "\t\t#import numpy as np\n",
      "\t\tdf['id']=np.where(df['id'].eq(0),df['ref'],df['id'])\n",
      "\t\t\n",
      "\t\t----------------------------------------------------------------------\n",
      "\t]\n",
      "}\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\"qid\": 68231389\n",
      "\"link\": https://stackoverflow.com/questions/68231389/compare-two-columns-that-contains-timestamps-in-pandas\n",
      "\"question\": {\n",
      "\t\"title\": Compare two columns that contains timestamps in pandas\n",
      "\t\"desc\": Lets say I have a dataframe like this one: I want to compare if the timestamp in Col1 is greater than in Col2 and if that is true I want to remove the timestamps from the other columns (Col2, Col3, Col4). I also want to check if timestamp in Col2 is greater than in Col3 and if that is true I want to remove timestamp from other columns Col3, Col4). I tried this one: But it is showing me this error: My desirable output would look like this: EDITED: Added Col0 \n",
      "}\n",
      "\"io\": {\n",
      "\t\"Frame-1\": \n",
      "\t\t  Col0       Col1                    Col2                   Col3                   Col4\n",
      "\t\t   1.txt  2021-06-23 15:04:30   2021-06-23 14:10:30   2021-06-23 14:15:30   2021-06-23 14:20:30\n",
      "\t\t   2.txt  2021-06-23 14:25:30   2021-06-23 15:30:30   2021-06-23 14:35:30   2021-06-23 14:40:30\n",
      "\t\t\n",
      "\t\"Frame-2\":\n",
      "\t\t  Col0       Col1                    Col2               Col3                   Col4\n",
      "\t\t   1.txt  2021-06-23 15:04:30        NaN                 NaN                    NaN\n",
      "\t\t   2.txt  2021-06-23 14:25:30   2021-06-23 15:30:30      NaN                    NaN\n",
      "\t\t\n",
      "}\n",
      "\"answer\": {\n",
      "\t\"desc\": %s A straightforward way with boolean mask: \n",
      "\t\"code-snippets\": [\n",
      "\t\tdt = df.select_dtypes('datetime')\n",
      "\t\tdt = dt.mask(dt.lt(dt.shift(axis=1)).cumsum(axis=1).astype(bool))\n",
      "\t\t\n",
      "\t\tdf.loc[:, dt.columns.tolist()] = dt\n",
      "\t\t\n",
      "\t\t----------------------------------------------------------------------\n",
      "\t]\n",
      "}\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\"qid\": 68231104\n",
      "\"link\": https://stackoverflow.com/questions/68231104/extract-part-of-a-3-d-dataframe\n",
      "\"question\": {\n",
      "\t\"title\": Extract part of a 3 D dataframe\n",
      "\t\"desc\": I have a 3d dataframe. looks like this: How could I extract only column A & B from every d1,d2.....? I desire to take the dataframe like this: \n",
      "}\n",
      "\"io\": {\n",
      "\t\"Frame-1\": \n",
      "\t\t     d1        d2            d3\n",
      "\t\t   A B C D...   A B C D...   A B C D..\n",
      "\t\t0  \n",
      "\t\t1\n",
      "\t\t2\n",
      "\t\t\n",
      "\t\"Frame-2\":\n",
      "\t\t    d1    d2    d3\n",
      "\t\t  A  B   A  B   A  B\n",
      "\t\t0\n",
      "\t\t1\n",
      "\t\t2\n",
      "\t\t\n",
      "}\n",
      "\"answer\": {\n",
      "\t\"desc\": %s Use on the level 1 values of columns then select with : : Sample Data Used: \n",
      "\t\"code-snippets\": [\n",
      "\t\tfiltered_df = df.loc[:, df.columns.isin(['A', 'B'], level=1)]\n",
      "\t\t\n",
      "\t\t----------------------------------------------------------------------\n",
      "\t\timport numpy as np\n",
      "\t\timport pandas as pd\n",
      "\t\t\n",
      "\t\tdf = pd.DataFrame(\n",
      "\t\t    np.arange(1, 25).reshape((-1, 8)),\n",
      "\t\t    columns=pd.MultiIndex.from_product((['d1', 'd2'], list('ABCD')))\n",
      "\t\t)\n",
      "\t\t\n",
      "\t\t----------------------------------------------------------------------\n",
      "\t]\n",
      "}\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\"qid\": 68229806\n",
      "\"link\": https://stackoverflow.com/questions/68229806/insert-values-from-variable-and-dataframe-into-another-dataframe\n",
      "\"question\": {\n",
      "\t\"title\": Insert values from variable and DataFrame into another DataFrame\n",
      "\t\"desc\": On start I have two DataFrames and one variable: I have to map id variable and the corresponding col0 cell from df1 DataFrame to all rows in df2 DataFrame. I tryed and as the result I made the code below: It seems to me that the code should work correctly, but unfortunatelly I have a NaN value in the col0 column. The expected result was: I've spent over an hour and can't figure out why I'm getting this kind of result. If possible, could you, please: explain briefly why I am getting the error fix my mistake in the code \n",
      "}\n",
      "\"io\": {\n",
      "\t\"Frame-1\": \n",
      "\t\t   id  col0  col1  col2\n",
      "\t\t0   1   3.0    13    23\n",
      "\t\t1   1   NaN    14    24\n",
      "\t\t2   1   NaN    15    25\n",
      "\t\t\n",
      "\t\"Frame-2\":\n",
      "\t\t   id  col0  col1  col2\n",
      "\t\t0   1   3.0    13    23\n",
      "\t\t1   1   3.0    14    24\n",
      "\t\t2   1   3.0    15    25\n",
      "\t\t\n",
      "}\n",
      "\"answer\": {\n",
      "\t\"desc\": %s Your mistake is on this string when you use this, it returns a Series type. Yes it just have a value, but is still a Series with just one value. To solve this issue is very very very simple, you just have to call the first item at the Series object like this: Your code with the ajustment must look like this Then your new df2 is like this: \n",
      "\t\"code-snippets\": [\n",
      "\t\timport pandas as pd\n",
      "\t\t\n",
      "\t\tid=1\n",
      "\t\tdf1 = pd.DataFrame({'id': [1, 2], 'col0': [3, 4]})\n",
      "\t\tdf2 = pd.DataFrame({'col1': [13, 14, 15],'col2': [23, 24, 25]})\n",
      "\t\t\n",
      "\t\tdf2.insert(0, \"id\", id)\n",
      "\t\tdf2.insert(1, \"col0\", df1[df1['id']==id]['col0'][0])\n",
      "\t\t\n",
      "\t\tprint(df2)\n",
      "\t\t\n",
      "\t\t----------------------------------------------------------------------\n",
      "\t]\n",
      "}\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\"qid\": 68213612\n",
      "\"link\": https://stackoverflow.com/questions/68213612/how-to-combine-rows-in-a-dataframe-in-a-pairwise-fashion-while-applying-some-fun\n",
      "\"question\": {\n",
      "\t\"title\": How to combine rows in a dataframe in a pairwise fashion while applying some function\n",
      "\t\"desc\": I have a dataframe that stores keys as ID, and some numerical values in Val1/Val2: I would like to go over this dataframe and combine the rows pairwise while getting the averages of Val1/Val2 for rows with the same ID. A suffix should be appended to the new row's ID based on which number pair it is. Here is the resulting dataframe: In this example, there are only 3 rows left. (id0, 10, 20) gets averaged with (id0,11,19) and combined into one row. (id1,5,5) gets averaged with (id1,1,1,) and (id1,1,1) gets averaged with (id1,2,4) to form 2 remaining rows. I can think of an iterative approach to this, but that would be very slow. How could I do this in a proper pythonic/pandas way? Code: \n",
      "}\n",
      "\"io\": {\n",
      "\t\"Frame-1\": \n",
      "\t\tID    Val1    Val2\n",
      "\t\tid0     10      20\n",
      "\t\tid0     11      19\n",
      "\t\tid1      5       5\n",
      "\t\tid1      1       1\n",
      "\t\tid1      2       4\n",
      "\t\t\n",
      "\t\"Frame-2\":\n",
      "\t\tID      Val1    Val2\n",
      "\t\tid0_1   10.5    19.5\n",
      "\t\tid1_1   3       3\n",
      "\t\tid1_2   1.5     2.5\n",
      "\t\t\n",
      "}\n",
      "\"answer\": {\n",
      "\t\"desc\": %s You can use after grouping by : \n",
      "\t\"code-snippets\": [\n",
      "\t\tout = df.groupby('ID').rolling(2).mean() \\\n",
      "\t\t        .dropna(how='all').reset_index(level=1, drop=True)\n",
      "\t\t\n",
      "\t\tout.index += '_' + out.groupby(level=0).cumcount().add(1).astype(str)\n",
      "\t\t\n",
      "\t\t----------------------------------------------------------------------\n",
      "\t]\n",
      "}\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\"qid\": 68211888\n",
      "\"link\": https://stackoverflow.com/questions/68211888/loop-through-multiple-small-pandas-dataframes-and-create-summary-dataframes-base\n",
      "\"question\": {\n",
      "\t\"title\": Loop through multiple small Pandas dataframes and create summary dataframes based on a single column\n",
      "\t\"desc\": I have a bunch of small dataframes each representing a single match in a game. I would like to take these dataframes and consolidate them into a single dataframe for each player without knowing the player's names ahead of time. The starting dataframes look like this: And I would like to get to a series of frames looking like this My problem is that the solutions that I've found so far all require me to know the player names ahead of time and manually set up a dataframe for each player. Since I'll be working with 40-50 players and I won't know all their names until I have the raw data I'd like to avoid that if at all possible. I have a loose plan to create a dictionary of players with each player key containing a dict of their rows from the dataframes. Once all the match dataframes are processed I would convert the dict of dicts into individual player dataframes. I'm not sure if this is the best approach though and am hoping that there's a more efficient way to do this. \n",
      "}\n",
      "\"io\": {\n",
      "\t\"Frame-1\": \n",
      "\t\tNAME     VAL1  VAL2  VAL3\n",
      "\t\tplayer1  3     5     7\n",
      "\t\tplayer2  2     6     8\n",
      "\t\tplayer3  3     6     7\n",
      "\t\t\n",
      "\t\tNAME     VAL1  VAL2  VAL3\n",
      "\t\tplayer2  5     7     7\n",
      "\t\tplayer3  2     6     8\n",
      "\t\tplayer5  3     6     7\n",
      "\t\t\n",
      "\t\"Frame-2\":\n",
      "\t\tNAME     VAL1  VAL2  VAL3\n",
      "\t\tplayer1  3     5     7\n",
      "\t\t\n",
      "\t\tNAME     VAL1  VAL2  VAL3\n",
      "\t\tplayer2  2     6     8\n",
      "\t\tplayer2  5     7     7\n",
      "\t\t\n",
      "\t\tNAME     VAL1  VAL2  VAL3\n",
      "\t\tplayer3  3     6     7\n",
      "\t\tplayer3  2     6     8\n",
      "\t\t\n",
      "\t\tNAME     VAL1  VAL2  VAL3\n",
      "\t\tplayer5  3     6     7\n",
      "\t\t\n",
      "}\n",
      "\"answer\": {\n",
      "\t\"desc\": %s Let's try + then build out a : : Each player's DataFrame can then be accessed like: : Or as a : : Each player's DataFrame can then be accessed like: : \n",
      "\t\"code-snippets\": [\n",
      "\t\tdfs = {group_name: df_\n",
      "\t\t       for group_name, df_ in pd.concat([df1, df2]).groupby('NAME')}\n",
      "\t\t\n",
      "\t\t----------------------------------------------------------------------\n",
      "\t\tdfs = [df_ for _, df_ in pd.concat([df1, df2]).groupby('NAME')]\n",
      "\t\t\n",
      "\t\t----------------------------------------------------------------------\n",
      "\t]\n",
      "}\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\"qid\": 68193558\n",
      "\"link\": https://stackoverflow.com/questions/68193558/pandas-group-many-columns-to-one-column-where-every-cell-is-a-list-of-values\n",
      "\"question\": {\n",
      "\t\"title\": pandas group many columns to one column where every cell is a list of values\n",
      "\t\"desc\": I have the dataframe And I want to group all columns to a single list that will be the only columns, so I will get: (Shape of df was change from (3,5) to (3,1)) What is the best way to do this? \n",
      "}\n",
      "\"io\": {\n",
      "\t\"Frame-1\": \n",
      "\t\tdf = \n",
      "\t\tc1 c2 c3 c4 c5\n",
      "\t\t1.  2. 3. 1. 5\n",
      "\t\t8.  2. 1. 3. 8\n",
      "\t\t4.  9. 1  2. 3\n",
      "\t\t\n",
      "\t\"Frame-2\":\n",
      "\t\tdf = \n",
      "\t\t    l\n",
      "\t\t[1,2,3,1,5]\n",
      "\t\t[8,2,1,3,8]\n",
      "\t\t[4,9,1,2,3]\n",
      "\t\t\n",
      "}\n",
      "\"answer\": {\n",
      "\t\"desc\": %s Try: \n",
      "\t\"code-snippets\": [\n",
      "\t\t#best way:\n",
      "\t\tdf['l']=df.values.tolist()\n",
      "\t\t#OR\n",
      "\t\tdf['l']=df.to_numpy().tolist()\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t#another way:\n",
      "\t\tdf['l']=df.agg(list,1)\n",
      "\t\t#OR\n",
      "\t\tdf['l']=df.apply(list,1)\n",
      "\t\t\n",
      "\t\t----------------------------------------------------------------------\n",
      "\t]\n",
      "}\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\"qid\": 68193521\n",
      "\"link\": https://stackoverflow.com/questions/68193521/concatenate-values-and-column-names-in-a-data-frame-to-create-a-new-data-frame\n",
      "\"question\": {\n",
      "\t\"title\": Concatenate values and column names in a data frame to create a new data frame\n",
      "\t\"desc\": I have the following data frame(): I need to derive the data frame() from such that column 1 of will have concatenated raw values of Value column with column names of Col 1 to Col 3. Column 2 of will have the raw value corresponding to each concatenated column name, Below is the sample which require to generate. : I have followed the below steps to derive df2 from df1. But this process seems a bit long. Any recommendations on shortening the process? Below is the code I have used \n",
      "}\n",
      "\"io\": {\n",
      "\t\"Frame-1\": \n",
      "\t\t  Value col1 col2 col3\n",
      "\t\t0     a   aa   ab   ac\n",
      "\t\t1     b   ba   bb   bc\n",
      "\t\t2     c   ca   cb   cc\n",
      "\t\t3     d   da   db   dc\n",
      "\t\t4     e   ea   eb   ec\n",
      "\t\t\n",
      "\t\"Frame-2\":\n",
      "\t\t      Value Col 1\n",
      "\t\t0   a_Col 1    aa\n",
      "\t\t1   a_Col 2    ab\n",
      "\t\t2   a_Col 3    ac\n",
      "\t\t3   b_Col 1    ba\n",
      "\t\t4   b_Col 2    bb\n",
      "\t\t5   b_Col 3    bc\n",
      "\t\t6   c_Col 1    ca\n",
      "\t\t7   c_Col 2    cb\n",
      "\t\t8   c_Col 3    cc\n",
      "\t\t9   d_Col 1    da\n",
      "\t\t10  d_Col 2    db\n",
      "\t\t11  d_Col 3    dc\n",
      "\t\t12  e_Col 1    ea\n",
      "\t\t13  e_Col 2    eb\n",
      "\t\t14  e_Col 3    ec\n",
      "\t\t\n",
      "}\n",
      "\"answer\": {\n",
      "\t\"desc\": %s Try: Prints: Optionally, you can sort values afterwards: \n",
      "\t\"code-snippets\": [\n",
      "\t\tx = df.melt(\"Value\", value_name=\"Col 1\")\n",
      "\t\tx.Value += \"_\" + x.variable\n",
      "\t\tx = x.drop(columns=\"variable\")\n",
      "\t\tprint(x)\n",
      "\t\t\n",
      "\t\t----------------------------------------------------------------------\n",
      "\t]\n",
      "}\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\"qid\": 68174614\n",
      "\"link\": https://stackoverflow.com/questions/68174614/why-does-it-add-0-to-the-value-while-converting-dataframe-columns-to-json\n",
      "\"question\": {\n",
      "\t\"title\": Why does it add .0 to the value while converting Dataframe columns to JSON\n",
      "\t\"desc\": I have the following DataFrame: df : to convert to JSON , I write following snippet: I get following output: total Why is that extra .0 is added to the result ? How do I remove that extra .0 ? \n",
      "}\n",
      "\"io\": {\n",
      "\t\"Frame-1\": \n",
      "\t\tA   B   C   D\n",
      "\t\t2   6   5   8.0\n",
      "\t\t6   11  2   3.6 \n",
      "\t\t1   5   7   5.2\n",
      "\t\t\n",
      "\t\"Frame-2\":\n",
      "\t\t{\"A\":2.0, \"B\":6.0, \"C\":5.0, \"D\":8.0}\n",
      "\t\t{\"A\":6.0, \"B\":11.0, \"C\":2.0, \"D\":3.6}\n",
      "\t\t{\"A\":1.0, \"B\":5.0, \"C\":7.0, \"D\":5.2}\n",
      "\t\t\n",
      "}\n",
      "\"answer\": {\n",
      "\t\"desc\": %s The problem here is, when you call apply on , pandas creates a Series out of it and upcasts the values because it is a single Series. For example consider following Series: As you can see, the entire series is converted to float because integer type can not hold all the values for the above series, similar is the case when you call apply on axis=1, it is same to : There's already an issue DataFrame.apply unintuitively changes int to float because of another column on github for this upcasting behavior of pandas . So, one possible option for you is as I have mentioned in the comment, to call on the entire dataframe as: A working solution for you may be using python's module alongwith , but remember, it does the same thing twice so it may be a bit slow for a large dataframes, however, you will get the data in the rquired format: OUTPUT: \n",
      "\t\"code-snippets\": [\n",
      "\t\tdf.iloc[0]\n",
      "\t\tA    2.0\n",
      "\t\tB    6.0\n",
      "\t\tC    5.0\n",
      "\t\tD    8.0\n",
      "\t\tName: 0, dtype: float64\n",
      "\t\t\n",
      "\t\t----------------------------------------------------------------------\n",
      "\t]\n",
      "}\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\"qid\": 68174113\n",
      "\"link\": https://stackoverflow.com/questions/68174113/map-numeric-data-into-bins-in-pandas-dataframe-for-seperate-groups-using-diction\n",
      "\"question\": {\n",
      "\t\"title\": Map numeric data into bins in Pandas dataframe for seperate groups using dictionaries\n",
      "\t\"desc\": I have a pandas dataframe as follows: I need to reclassify the 'value' column separately for each 'polyid'. For the reclassification, I have two dictionaries. One with the bins that contain the information on how I want to cut the 'values' for each 'polyid' separately: And one with the ids with which I want to label the resulting bins: I tried to get this answer to work for my use case. I could only come up with applying on each 'polyid' subset and then all subsets again back to one dataframe: This results in my desired output: However, the line: raises the warning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead that I am unable to solve with using . Also, I guess there generally is a more efficient way of doing this without having to loop over each category? \n",
      "}\n",
      "\"io\": {\n",
      "\t\"Frame-1\": \n",
      "\t\tbins_dic = {1:[0,0.6,0.8,1], 2:[0,0.2,0.9,1], 3:[0,0.5,0.6,1]}\n",
      "\t\t\n",
      "\t\"Frame-2\":\n",
      "\t\tids_dic = {1:[1,2,3], 2:[1,2,3], 3:[1,2,3]}\n",
      "\t\t\n",
      "}\n",
      "\"answer\": {\n",
      "\t\"desc\": %s A simpler solution would be to use and a custom function on each group. In this case, we can define a function that obtains the correct bins and ids and then uses : Result: \n",
      "\t\"code-snippets\": [\n",
      "\t\tdef reclass(group, name):\n",
      "\t\t    bins = bins_dic[name]\n",
      "\t\t    ids = ids_dic[name]\n",
      "\t\t    return pd.cut(group, bins, labels=ids)\n",
      "\t\t    \n",
      "\t\tdf['id'] = df.groupby('polyid')['value'].apply(lambda x: reclass(x, x.name))\n",
      "\t\t\n",
      "\t\t----------------------------------------------------------------------\n",
      "\t]\n",
      "}\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\"qid\": 68150020\n",
      "\"link\": https://stackoverflow.com/questions/68150020/getting-first-second-third-value-in-row-of-numpy-array-after-nan-using-vector\n",
      "\"question\": {\n",
      "\t\"title\": Getting first/second/third... value in row of numpy array after nan using vectorization\n",
      "\t\"desc\": I have the following : I have partly acomplished what I am trying to do here using Pandas alone but the process takes ages so I am having to use (see Getting the nearest values to the left in a pandas column) and that is where I am struggling. Essentialy, I want my function which takes an argument , to capture the first non value for each row from the left, and return the whole thing as a array/vector so that: As I have described in the other post, its best to imagine a horizontal line being drawn from the left for each row, and returning the values intersected by that line as an array. then returns the first value (in that array) and will return the second value intersected and so on. Therefore: The solution proposed in the post above is very effective: However this is very slow with larger iterations. I have tried this with and its even slower! Is there a fatser way with vectorization? Many thanks. \n",
      "}\n",
      "\"io\": {\n",
      "\t\"Frame-1\": \n",
      "\t\tf(offset=0)\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t| 0  | 1  |\n",
      "\t\t| -- | -- |\n",
      "\t\t| 1  | 25 |\n",
      "\t\t| 2  | 29 |\n",
      "\t\t| 3  | 33 |\n",
      "\t\t| 4  | 31 |\n",
      "\t\t| 5  | 30 |\n",
      "\t\t| 6  | 35 |\n",
      "\t\t| 7  | 31 |\n",
      "\t\t| 8  | 33 |\n",
      "\t\t| 9  | 26 |\n",
      "\t\t| 10 | 27 |\n",
      "\t\t| 11 | 35 |\n",
      "\t\t| 12 | 33 |\n",
      "\t\t| 13 | 28 |\n",
      "\t\t| 14 | 25 |\n",
      "\t\t| 15 | 25 |\n",
      "\t\t| 16 | 26 |\n",
      "\t\t| 17 | 34 |\n",
      "\t\t| 18 | 28 |\n",
      "\t\t| 19 | 34 |\n",
      "\t\t| 20 | 28 |\n",
      "\t\t\n",
      "\t\"Frame-2\":\n",
      "\t\tf(offset=1)\n",
      "\t\t\n",
      "\t\t| 0  | 1   |\n",
      "\t\t| -- | --- |\n",
      "\t\t| 1  | nan |\n",
      "\t\t| 2  | nan |\n",
      "\t\t| 3  | nan |\n",
      "\t\t| 4  | 35  |\n",
      "\t\t| 5  | 34  |\n",
      "\t\t| 6  | 34  |\n",
      "\t\t| 7  | 26  |\n",
      "\t\t| 8  | 25  |\n",
      "\t\t| 9  | 31  |\n",
      "\t\t| 10 | 26  |\n",
      "\t\t| 11 | 25  |\n",
      "\t\t| 12 | 35  |\n",
      "\t\t| 13 | 25  |\n",
      "\t\t| 14 | 25  |\n",
      "\t\t| 15 | 26  |\n",
      "\t\t| 16 | 31  |\n",
      "\t\t| 17 | 29  |\n",
      "\t\t| 18 | 29  |\n",
      "\t\t| 19 | 26  |\n",
      "\t\t| 20 | 30  |\n",
      "\t\t\n",
      "}\n",
      "\"answer\": {\n",
      "\t\"desc\": %s Numpy approach We can define a function which takes a array and (n) as input arguments and returns array. Basically, for each row it returns the value after the first value Pandas approach We can the dataframe to reshape then group the dataframe on and aggregate using , then to conform the index of aggregated frame according to original frame Sample run Performance Numpy based approach is approximately faster than the given approach while pandas based approach is approximately faster \n",
      "\t\"code-snippets\": [\n",
      "\t\tdef first_valid(arr, offset=0):\n",
      "\t\t    m = ~np.isnan(arr)\n",
      "\t\t    i =  m.argmax(axis=1) + offset\n",
      "\t\t    iy = np.clip(i, 0, arr.shape[1] - 1)\n",
      "\t\t\n",
      "\t\t    vals = arr[np.r_[:arr.shape[0]], iy]\n",
      "\t\t    vals[(~m.any(1)) | (i >= arr.shape[1])] = np.nan\n",
      "\t\t    return vals\n",
      "\t\t\n",
      "\t\t----------------------------------------------------------------------\n",
      "\t\tdef first_valid(df, offset=0):\n",
      "\t\t    return df.stack().groupby(level=0)\\\n",
      "\t\t                     .nth(offset).reindex(df.index)\n",
      "\t\t\n",
      "\t\t----------------------------------------------------------------------\n",
      "\t\t# Sample dataframe for testing purpose\n",
      "\t\tdf_test = pd.concat([df] * 10000, ignore_index=True)\n",
      "\t\t\n",
      "\t\t%%timeit # Numpy approach\n",
      "\t\t_ = first_valid(df_test.to_numpy(), 1)\n",
      "\t\t# 6.9 ms ± 212 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t%%timeit # Pandas approach\n",
      "\t\t_ = first_valid(df_test, 1)\n",
      "\t\t# 90 ms ± 867 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t%%timeit # OP's approach\n",
      "\t\t_ = f(df_test, 1)\n",
      "\t\t# 2.03 s ± 183 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\t\t\n",
      "\t\t----------------------------------------------------------------------\n",
      "\t]\n",
      "}\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\"qid\": 57033657\n",
      "\"link\": https://stackoverflow.com/questions/57033657/how-to-extract-month-name-and-year-from-date-column-of-dataframe\n",
      "\"question\": {\n",
      "\t\"title\": How to Extract Month Name and Year from Date column of DataFrame\n",
      "\t\"desc\": I have the following DF I want to extract the month name and year in a simple way in the following format: I have used the which return format. \n",
      "}\n",
      "\"io\": {\n",
      "\t\"Frame-1\": \n",
      "\t\t45    2018-01-01\n",
      "\t\t73    2018-02-08\n",
      "\t\t74    2018-02-08\n",
      "\t\t75    2018-02-08\n",
      "\t\t76    2018-02-08\n",
      "\t\t\n",
      "\t\"Frame-2\":\n",
      "\t\t45    Jan-2018\n",
      "\t\t73    Feb-2018\n",
      "\t\t74    Feb-2018\n",
      "\t\t75    Feb-2018\n",
      "\t\t76    Feb-2018\n",
      "\t\t\n",
      "}\n",
      "\"answer\": {\n",
      "\t\"desc\": %s Cast you date from object to actual datetime and use dt to access what you need. \n",
      "\t\"code-snippets\": [\n",
      "\t\timport pandas as pd\n",
      "\t\t\n",
      "\t\tdf = pd.DataFrame({'Date':['2019-01-01','2019-02-08']})\n",
      "\t\t\n",
      "\t\tdf['Date'] = pd.to_datetime(df['Date'])\n",
      "\t\t\n",
      "\t\t# You can format your date as you wish\n",
      "\t\tdf['Mon_Year'] = df['Date'].dt.strftime('%b-%Y')\n",
      "\t\t\n",
      "\t\t# the result is object/string unlike `.dt.to_period('M')` that retains datetime data type.\n",
      "\t\t\n",
      "\t\tprint(df['Mon_Year'])\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t----------------------------------------------------------------------\n",
      "\t]\n",
      "}\n",
      "====================================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "for a in taken_answers:\n",
    "    fmt_input = a[\"formatted_input\"]\n",
    "    print(\"\\\"qid\\\": %s\" % fmt_input[\"qid\"])\n",
    "    print(\"\\\"link\\\": %s\" % fmt_input[\"link\"])\n",
    "    print(\"\\\"question\\\": {\")\n",
    "    print(\"\\t\\\"title\\\": %s\" % fmt_input[\"question\"][\"title\"])\n",
    "    print(\"\\t\\\"desc\\\": %s\" % fmt_input[\"question\"][\"ques_desc\"])\n",
    "    print(\"}\")\n",
    "    print(\"\\\"io\\\": {\")\n",
    "    print(\"\\t\\\"Frame-1\\\": \")\n",
    "    print_formatted_code(fmt_input[\"io\"][0])\n",
    "    print(\"\\t\\\"Frame-2\\\":\")\n",
    "    print_formatted_code(fmt_input[\"io\"][1])\n",
    "    print(\"}\")\n",
    "    print(\"\\\"answer\\\": {\")\n",
    "    print(\"\\t\\\"desc\\\": %s\", fmt_input[\"answer\"][\"ans_desc\"])\n",
    "    print(\"\\t\\\"code-snippets\\\": [\")\n",
    "    for t in fmt_input[\"answer\"][\"code\"]:\n",
    "        print_formatted_code(t)\n",
    "        print(\"\\t\\t\" + (\"-\" * 70))\n",
    "    print(\"\\t]\")\n",
    "    print(\"}\")\n",
    "    print(\"=\" * 100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_answers_file = open(\"outputs/all_accepted_answers_with_all_details.json\", 'w')\n",
    "json.dump(obj=accepted_answers, fp=all_answers_file, indent=4)\n",
    "all_answers_file.close()\n",
    "\n",
    "taken_answer_file = open(\"outputs/taken_answers_with_all_details.json\", \"w\")\n",
    "json.dump(obj=taken_answers, fp=taken_answer_file, indent=4)\n",
    "taken_answer_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# questions = []\n",
    "# for pi in range(1, 21):\n",
    "#     d = SITE.fetch(\n",
    "#             \"search/advanced\", \n",
    "#             q=\"pandas,dataframe\", \n",
    "#             accepted=True, \n",
    "#             tagged=\"pandas;dataframe;python\", \n",
    "#             page=pi, \n",
    "#             filter=\"withbody\"\n",
    "#         )['items']\n",
    "#     for itm in d:\n",
    "#         if 'accepted_answer_id' in itm.keys() and 'pandas' in itm['tags'] and 'dataframe' in itm['tags']:\n",
    "#             questions.append(itm)\n",
    "#     print(len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.makedirs('ten_thousand_questions', exist_ok=True)\n",
    "# ten_thousand_questions = open('ten_thousand_questions/questions_with_bodies.json', 'w')\n",
    "# json.dump(questions, fp=ten_thousand_questions, indent=4)\n",
    "# ten_thousand_questions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
