{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "post_data = json.load(open('./post-query.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['items', 'has_more', 'quota_max', 'quota_remaining'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_answers = []\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "post_data['items'][0]['is_answered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae105d7f6e7453dac61b49765c90172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(post_data['items']):\n",
    "    if 'accepted_answer_id' in item:\n",
    "        accepted_answers.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accepted_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tags': ['python', 'pandas'],\n",
       "  'owner': {'reputation': 1986,\n",
       "   'user_id': 3952994,\n",
       "   'user_type': 'registered',\n",
       "   'accept_rate': 76,\n",
       "   'profile_image': 'https://www.gravatar.com/avatar/c2fc6a69e19964667f321ec499bdb18c?s=128&d=identicon&r=PG&f=1',\n",
       "   'display_name': 'HungUnicorn',\n",
       "   'link': 'https://stackoverflow.com/users/3952994/hungunicorn'},\n",
       "  'is_answered': True,\n",
       "  'view_count': 92740,\n",
       "  'accepted_answer_id': 33975750,\n",
       "  'answer_count': 5,\n",
       "  'score': 63,\n",
       "  'last_activity_date': 1624325486,\n",
       "  'creation_date': 1448639975,\n",
       "  'last_edit_date': 1501953154,\n",
       "  'question_id': 33961028,\n",
       "  'content_license': 'CC BY-SA 3.0',\n",
       "  'link': 'https://stackoverflow.com/questions/33961028/remove-non-numeric-rows-in-one-column-with-pandas',\n",
       "  'title': 'Remove non-numeric rows in one column with pandas'},\n",
       " {'tags': ['python', 'python-3.x', 'pandas'],\n",
       "  'owner': {'reputation': 355,\n",
       "   'user_id': 11229812,\n",
       "   'user_type': 'registered',\n",
       "   'profile_image': 'https://www.gravatar.com/avatar/af43f63e133071a6d2b66db9162b784c?s=128&d=identicon&r=PG&f=1',\n",
       "   'display_name': 'Slavisha84',\n",
       "   'link': 'https://stackoverflow.com/users/11229812/slavisha84'},\n",
       "  'is_answered': True,\n",
       "  'view_count': 17,\n",
       "  'accepted_answer_id': 68075472,\n",
       "  'answer_count': 1,\n",
       "  'score': 0,\n",
       "  'last_activity_date': 1624315007,\n",
       "  'creation_date': 1624313658,\n",
       "  'question_id': 68075343,\n",
       "  'content_license': 'CC BY-SA 4.0',\n",
       "  'link': 'https://stackoverflow.com/questions/68075343/python-how-to-export-monthly-data-into-excel-based-on-month',\n",
       "  'title': 'Python - How to export monthly data into excel based on month?'},\n",
       " {'tags': ['python', 'pandas', 'dataframe'],\n",
       "  'owner': {'reputation': 37,\n",
       "   'user_id': 15835538,\n",
       "   'user_type': 'registered',\n",
       "   'profile_image': 'https://lh3.googleusercontent.com/a/AATXAJzT_UHWoJVd3VMGtAtysxpirR3g4bChl1rkzT4H=k-s128',\n",
       "   'display_name': 'Santiago Ramirez',\n",
       "   'link': 'https://stackoverflow.com/users/15835538/santiago-ramirez'},\n",
       "  'is_answered': True,\n",
       "  'view_count': 29,\n",
       "  'accepted_answer_id': 68074148,\n",
       "  'answer_count': 1,\n",
       "  'score': 0,\n",
       "  'last_activity_date': 1624312122,\n",
       "  'creation_date': 1624304935,\n",
       "  'last_edit_date': 1624308277,\n",
       "  'question_id': 68073899,\n",
       "  'content_license': 'CC BY-SA 4.0',\n",
       "  'link': 'https://stackoverflow.com/questions/68073899/erasing-outliers-from-a-dataframe-in-python',\n",
       "  'title': 'Erasing outliers from a dataframe in python'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'backoff': 0, 'has_more': False, 'page': 1, 'quota_max': 300, 'quota_remaining': 284, 'total': 0, 'items': [{'owner': {'reputation': 26, 'user_id': 12661819, 'user_type': 'registered', 'profile_image': 'https://www.gravatar.com/avatar/b1a94e11fee59e668e6d255bb5f7f2e1?s=128&d=identicon&r=PG&f=1', 'display_name': 'Dominik Berse', 'link': 'https://stackoverflow.com/users/12661819/dominik-berse'}, 'is_accepted': True, 'score': 1, 'last_activity_date': 1624315007, 'last_edit_date': 1624315007, 'creation_date': 1624314667, 'answer_id': 68075472, 'question_id': 68075343, 'content_license': 'CC BY-SA 4.0', 'body': '<p>You might want to have a look <a href=\"https://stackoverflow.com/a/59604826/12661819\">here</a>. You can use simple integers to address the month, so you should be able to iterate like this (not tested):</p>\\n<pre><code>for month in range(1, 13):\\n    df_per_month = df[df[\\'Date\\'].dt.month == month]\\n    df_per_month.to_excel(f\\'{month}.xlsx\\')\\n</code></pre>\\n<p>Edit: Note that according to <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month.html\" rel=\"nofollow noreferrer\">docs</a>, <code>month</code> ranges from 1-12.</p>\\n<p>Also, if you want to iterate month <em>and</em> year, you would have to do something like:</p>\\n<pre><code>for year in range(2018, 2022):\\n    for month in range(1, 13):\\n        data = df[(df[\\'Date\\'].dt.month == month) &amp; (df[\\'Date\\'].dt.year == year)]\\n        data.to_excel(f\\'{month}-{year}.xlsx\\')\\n</code></pre>\\n'}, {'owner': {'reputation': 538, 'user_id': 8081835, 'user_type': 'registered', 'profile_image': 'https://i.stack.imgur.com/wPe2c.jpg?s=128&g=1', 'display_name': 'Mateusz Dorobek', 'link': 'https://stackoverflow.com/users/8081835/mateusz-dorobek'}, 'is_accepted': True, 'score': 1, 'last_activity_date': 1624312122, 'last_edit_date': 1624312122, 'creation_date': 1624306423, 'answer_id': 68074148, 'question_id': 68073899, 'content_license': 'CC BY-SA 4.0', 'body': '<pre class=\"lang-py prettyprint-override\"><code>df = pd.read_csv(&quot;data.csv&quot;)\\nX = df[[\\'height\\', \\'weight\\']]\\nX.plot(kind=\\'scatter\\', x=\\'weight\\', y=\\'height\\', colormap=\\'viridis\\')\\nplt.show()\\n</code></pre>\\n<p><a href=\"https://i.stack.imgur.com/sCKWF.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/sCKWF.png\" alt=\"enter image description here\" /></a></p>\\n<pre class=\"lang-py prettyprint-override\"><code>knn = NearestNeighbors(n_neighbors=2).fit(X)\\ndistances, indices = knn.kneighbors(X)\\nX[\\'distances\\'] = distances[:,1]\\nX.distances\\n0       1.000000\\n1       1.000000\\n2       1.000000\\n3       3.000000\\n4       1.000000\\n5       1.000000\\n6     133.958949\\n7     100.344407\\n       ...\\n</code></pre>\\n<pre class=\"lang-py prettyprint-override\"><code>X.plot(kind=\\'scatter\\', x=\\'weight\\', y=\\'height\\', c=\\'distances\\', colormap=\\'viridis\\')\\nplt.show()\\n</code></pre>\\n<p><a href=\"https://i.stack.imgur.com/PtkKN.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PtkKN.png\" alt=\"enter image description here\" /></a></p>\\n<pre class=\"lang-py prettyprint-override\"><code>MAX_DIST = 10\\nX[distances &lt; MAX_DIST]\\n    height  weight\\n0   162 78.0\\n1   162 78.0\\n2   151 76.0\\n3   151 76.0\\n4   171 84.0\\n...\\n</code></pre>\\n<p>And finally to filter out all the outliers:</p>\\n<pre class=\"lang-py prettyprint-override\"><code>MAX_DIST = 10\\nX = X[X.distances &lt; MAX_DIST]\\n</code></pre>\\n'}, {'owner': {'reputation': 24486, 'user_id': 4542359, 'user_type': 'registered', 'accept_rate': 90, 'profile_image': 'https://www.gravatar.com/avatar/a6ea331ac684b52563d13e6ee44e03be?s=128&d=identicon&r=PG&f=1', 'display_name': 'Anton Protopopov', 'link': 'https://stackoverflow.com/users/4542359/anton-protopopov'}, 'is_accepted': True, 'score': 41, 'last_activity_date': 1540027540, 'last_edit_date': 1540027540, 'creation_date': 1448740388, 'answer_id': 33975750, 'question_id': 33961028, 'content_license': 'CC BY-SA 4.0', 'body': '<p>You could use standard  method of strings <a href=\"https://docs.python.org/3/library/stdtypes.html#str.isnumeric\" rel=\"noreferrer\"><code>isnumeric</code></a> and apply it to each value in your <code>id</code> column:</p>\\n\\n<pre><code>import pandas as pd\\nfrom io import StringIO\\n\\ndata = \"\"\"\\nid,name\\n1,A\\n2,B\\n3,C\\ntt,D\\n4,E\\n5,F\\nde,G\\n\"\"\"\\n\\ndf = pd.read_csv(StringIO(data))\\n\\nIn [55]: df\\nOut[55]: \\n   id name\\n0   1    A\\n1   2    B\\n2   3    C\\n3  tt    D\\n4   4    E\\n5   5    F\\n6  de    G\\n\\nIn [56]: df[df.id.apply(lambda x: x.isnumeric())]\\nOut[56]: \\n  id name\\n0  1    A\\n1  2    B\\n2  3    C\\n4  4    E\\n5  5    F\\n</code></pre>\\n\\n<p>Or if you want to use <code>id</code> as index you could do:</p>\\n\\n<pre><code>In [61]: df[df.id.apply(lambda x: x.isnumeric())].set_index(\\'id\\')\\nOut[61]: \\n   name\\nid     \\n1     A\\n2     B\\n3     C\\n4     E\\n5     F\\n</code></pre>\\n\\n<h3>Edit. Add timings</h3>\\n\\n<p>Although case with <code>pd.to_numeric</code> is not using <code>apply</code> method it is almost two times slower than with applying <code>np.isnumeric</code> for <code>str</code> columns. Also I add option with using pandas <a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.isnumeric.html\" rel=\"noreferrer\"><code>str.isnumeric</code></a> which is less typing and still faster then using <code>pd.to_numeric</code>. But <code>pd.to_numeric</code> is more general because it could work with any data types (not only strings).</p>\\n\\n<pre><code>df_big = pd.concat([df]*10000)\\n\\nIn [3]: df_big = pd.concat([df]*10000)\\n\\nIn [4]: df_big.shape\\nOut[4]: (70000, 2)\\n\\nIn [5]: %timeit df_big[df_big.id.apply(lambda x: x.isnumeric())]\\n15.3 ms ± 2.02 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\\n\\nIn [6]: %timeit df_big[df_big.id.str.isnumeric()]\\n20.3 ms ± 171 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\\n\\nIn [7]: %timeit df_big[pd.to_numeric(df_big[\\'id\\'], errors=\\'coerce\\').notnull()]\\n29.9 ms ± 682 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\\n</code></pre>\\n'}]}\n"
     ]
    }
   ],
   "source": [
    "from stackapi import StackAPI\n",
    "\n",
    "SITE = StackAPI('stackoverflow')\n",
    "aids = [i['accepted_answer_id'] for i in accepted_answers]\n",
    "answers = SITE.fetch('answers/{ids}', ids=aids, filter='withbody')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answer = answers['items']\n",
    "id_to_answer = {\n",
    "    answer['answer_id']: answer for answer in final_answer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(accepted_answers)):\n",
    "    accepted_answers[idx]['answer_body'] = id_to_answer[accepted_answers[idx]['accepted_answer_id']]['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qids = [i['question_id'] for i in accepted_answers]\n",
    "question_bodies = SITE.fetch('questions/{ids}', ids=qids, filter='withbody')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_items = question_bodies['items']\n",
    "id_to_body = {\n",
    "    q['question_id']: q['body'] for q in question_items\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(accepted_answers)):\n",
    "    accepted_answers[idx]['question_body'] = id_to_body[accepted_answers[idx]['question_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Mining Pandas APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe APIs only\n",
      "['DataFrame', 'index', 'columns', 'dtypes', 'info', 'select_dtypes', 'values', 'axes', 'ndim', 'size', 'shape', 'memory_usage', 'empty', 'set_flags', 'astype', 'convert_dtypes', 'infer_objects', 'copy', 'bool', 'head', 'at', 'iat', 'loc', 'iloc', 'insert', '__iter__', 'items', 'iteritems', 'keys', 'iterrows', 'itertuples', 'lookup', 'pop', 'tail', 'xs', 'get', 'isin', 'where', 'mask', 'query', 'add', 'sub', 'mul', 'div', 'truediv', 'floordiv', 'mod', 'pow', 'dot', 'radd', 'rsub', 'rmul', 'rdiv', 'rtruediv', 'rfloordiv', 'rmod', 'rpow', 'lt', 'gt', 'le', 'ge', 'ne', 'eq', 'combine', 'combine_first', 'apply', 'applymap', 'pipe', 'agg', 'aggregate', 'transform', 'groupby', 'rolling', 'expanding', 'ewm', 'abs', 'all', 'any', 'clip', 'corr', 'corrwith', 'count', 'cov', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'eval', 'kurt', 'kurtosis', 'mad', 'max', 'mean', 'median', 'min', 'mode', 'pct_change', 'prod', 'product', 'quantile', 'rank', 'round', 'sem', 'skew', 'sum', 'std', 'var', 'nunique', 'value_counts', 'add_prefix', 'add_suffix', 'align', 'at_time', 'between_time', 'drop', 'drop_duplicates', 'duplicated', 'equals', 'filter', 'first', 'head', 'idxmax', 'idxmin', 'last', 'reindex', 'reindex_like', 'rename', 'rename_axis', 'reset_index', 'sample', 'set_axis', 'set_index', 'tail', 'take', 'truncate', 'backfill', 'bfill', 'dropna', 'ffill', 'fillna', 'interpolate', 'isna', 'isnull', 'notna', 'notnull', 'pad', 'replace', 'droplevel', 'pivot', 'pivot_table', 'reorder_levels', 'sort_values', 'sort_index', 'nlargest', 'nsmallest', 'swaplevel', 'stack', 'unstack', 'swapaxes', 'melt', 'explode', 'squeeze', 'to_xarray', 'T', 'transpose', 'append', 'assign', 'compare', 'join', 'merge', 'update', 'asfreq', 'asof', 'shift', 'slice_shift', 'tshift', 'first_valid_index', 'last_valid_index', 'resample', 'to_period', 'to_timestamp', 'tz_convert', 'tz_localize', 'Flags', 'attrs', 'plot', 'plot.area', 'plot.bar', 'plot.barh', 'plot.box', 'plot.density', 'plot.hexbin', 'plot.hist', 'plot.kde', 'plot.line', 'plot.pie', 'plot.scatter', 'boxplot', 'hist', 'sparse.density', 'sparse.from_spmatrix', 'sparse.to_coo', 'sparse.to_dense', 'from_dict', 'from_records', 'to_parquet', 'to_pickle', 'to_csv', 'to_hdf', 'to_sql', 'to_dict', 'to_excel', 'to_json', 'to_html', 'to_feather', 'to_latex', 'to_stata', 'to_gbq', 'to_records', 'to_string', 'to_clipboard', 'to_markdown', 'style']\n",
      "====================================================================================================\n",
      "Pandas APIS\n",
      "['at', 'value_counts', 'utcnow', 'DatetimeArray', 'from_dict', 'last', 'filter', 'is_overlapping', 'indexer_at_time', 'read_sql_table', 'squeeze', 'dt.normalize', 'dt.nanoseconds', 'is_numeric', 'set_codes', 'CategoricalIndex', 'dt.dayofyear', 'dt.is_month_start', 'DatetimeTZDtype', 'str.rfind', 'from_breaks', 'concat', 'boxplot', 'dt.tz', 'start', 'to_sql', 'dt.is_year_end', 'T', 'set_index', 'flags', 'var', 'sparse.fill_value', 'is_mixed', 'radd', 'dt.floor', 'index', 'last_valid_index', 'backfill', 'set_flags', 'Int64Dtype', 'read_orc', 'is_month_end', 'compare', 'idxmax', 'is_floating', 'str.replace', 'nth', 'to_json', 'ohlc', 'UInt64Index', 'str.isdecimal', 'tzname', 'dt.nanosecond', 'isoweekday', 'IntervalIndex', 'duplicated', 'stack', 'floor', 'join', 'pow', 'get_indexer_for', 'str.join', 'day_name', 'plot.area', 'assign', 'head', 'to_excel', 'quarter', 'iloc', 'get_indexer', 'DataFrame', 'pivot', 'hasnans', 'get_loc_level', 'str.center', 'tzinfo', 'is_month_start', 'remove_unused_levels', 'BooleanArray', 'update', 'at_time', 'dtypes', 'rsub', 'utcfromtimestamp', 'droplevel', 'median', 'TimedeltaArray', 'as_unordered', 'fromordinal', 'dt.month', 'dt.start_time', 'Timedelta', 'PeriodIndex', 'get_value', 'day_of_year', 'delta', 'rtruediv', 'first', 'quantile', 'today', 'end_time', 'axes', 'wide_to_long', 'mad', 'inferred_freq', 'merge_asof', 'Flags', 'Index', 'pop', 'to_timedelta', 'cummax', 'select', 'plot.barh', 'read_hdf', 'dt.quarter', 'interpolate', 'read_sql_query', 'symmetric_difference', 'build_table_schema', 'rank', 'str.decode', 'add_prefix', 'closed', 'ewm', 'rename_categories', 'contains', 'rmul', 'set_names', 'length', 'cut', 'std', 'str.capitalize', 'asof_locs', 'dst', 'dt.weekday', 'parse', 'searchsorted', 'dt.year', 'max', 'ceil', 'from_arrays', 'is_year_start', 'dt.end_time', 'to_string', 'str.strip', 'to_tuples', 'truncate', 'dt.date', 'ne', 'asfreq', 'melt', 'putmask', 'gt', 'repeat', 'weekofyear', 'kurt', 'difference', 'abs', 'Int32Dtype', 'lt', 'is_unique', 'str.index', 'astimezone', 'replace', 'SparseArray', 'get_locs', 'mode', 'dt.month_name', 'str.wrap', 'iteritems', 'from_records', 'to_parquet', 'sum', 'read_fwf', 'SparseDtype', 'value_labels', 'dt.total_seconds', 'Int16Dtype', 'between', 'dt.day_of_year', 'dt.round', 'DatetimeIndex', 'time', 'levshape', 'bdate_range', 'dt.is_month_end', 'BooleanDtype', 'corr', 'week', 'to_frame', 'argmax', 'closed_left', 'get_indexer_non_unique', 'pct_change', 'isin', 'bfill', 'data_label', 'sparse.density', 'sample', 'str.casefold', 'add_categories', 'UInt32Dtype', 'seconds', 'read_parquet', 'add', 'describe', 'nlevels', 'to_series', 'str.lower', 'sem', 'ctime', 'is_monotonic_decreasing', 'to_dict', 'to_numeric', 'to_period', 'MultiIndex', 'astype', 'indexer_between_time', 'ngroup', 'to_pytimedelta', 'round', 'Float64Index', 'qcut', 'dot', 'is_interval', 'daysinmonth', 'cat.remove_unused_categories', 'PeriodArray', 'attrs', 'microsecond', 'merge_ordered', 'to_julian_date', 'UInt8Dtype', 'get_slice_bound', 'weekday', 'read_feather', 'set_axis', 'reindex_like', 'strftime', 'swapaxes', 'TimedeltaIndex', 'str.lstrip', 'str.partition', 'is_monotonic_increasing', 'identical', 'cat.reorder_categories', 'set_closed', 'str.startswith', 'qyear', 'values', 'plot.pie', 'agg', 'timetz', 'to_timestamp', 'apply', 'str.extract', 'sparse.from_spmatrix', 'mask', 'categories', 'sort_values', 'dt.days', 'dt.day_of_week', 'dt.second', 'read_pickle', 'rename_axis', 'dt.hour', 'map', 'str.encode', 'dropna', 'minute', 'hash_pandas_object', 'is_empty', 'str.rstrip', 'nbytes', 'bool', 'month', 'diff', 'memory_usage', 'sparse.to_dense', 'read_json', 'freqstr', 'UInt16Dtype', 'sortlevel', 'cumcount', 'remove_categories', 'itertuples', 'is_leap_year', 'transpose', 'item', 'to_datetime64', 'set_categories', 'iat', 'str.rpartition', 'nunique', 'components', 'sparse.sp_values', 'year', 'insert', 'nlargest', 'empty', 'to_markdown', 'read_html', 'closed_right', 'dayofyear', 'dt.weekofyear', 'left', 'Categorical', 'dt.tz_localize', 'Timestamp', 'expanding', 'ordered', 'str.endswith', 'rfloordiv', 'str.translate', 'transform', 'slice_shift', 'Grouper', 'overlaps', 'pipe', 'ordinal', 'isocalendar', 'tz', 'dt.dayofweek', 'select_dtypes', 'str.isalpha', 'iterrows', 'str.match', 'day_of_week', 'dt.to_period', 'dt.time', 'info', 'str.swapcase', 'dt.strftime', 'str.slice', 'dt.tz_convert', 'sparse.to_coo', 'str.extractall', 'str.isnumeric', 'Int64Index', 'resolution', 'as_ordered', 'day', 'timetuple', 'variable_labels', 'Series', 'plot', 'intersection', 'floordiv', 'dt.qyear', 'idxmin', 'to_gbq', 'str.ljust', 'dt.is_quarter_start', 'prod', 'month_name', 'rmod', 'is_quarter_start', 'loc', 'read_spss', 'hash_array', 'timedelta_range', 'dt.week', 'plot.hist', 'str.contains', 'test', 'to_datetime', 'merge', '__array__', 'combine', 'cat.ordered', 'to_pydatetime', 'from_tuples', 'to_records', 'is_quarter_end', 'fillna', 'all', 'truediv', 'items', 'ge', 'cov', 'str.islower', 'sparse.npoints', 'where', 'style', 'reindex', 'microseconds', 'div', 'to_hdf', 'to_timedelta64', 'ravel', 'open_right', 'cat.remove_categories', 'is_categorical', 'factorize', 'min', 'combine_first', 'total_seconds', 'date', 'utctimetuple', 'codes', 'IntegerArray', 'infer_objects', 'RangeIndex', 'rolling', 'right', 'CategoricalDtype', 'normalize', 'rpow', 'is_lexsorted', 'str.isdigit', 'clip', 'snap', 'get_dummies', 'fromtimestamp', 'name', 'add_suffix', 'asm8', 'StringDtype', 'mod', 'freq', 'days', 'indices', 'read_sas', 'to_html', 'drop', 'str.pad', 'from_product', 'cumprod', 'to_feather', 'plot.line', 'is_object', 'str.isupper', 'remove_unused_categories', 'to_numpy', 'append', 'eq', 'plot.bar', 'to_stata', 'json_normalize', 'StringArray', 'eval', 'convert_dtypes', 'ndim', 'str.slice_replace', 'str.rsplit', 'cat.add_categories', 'drop_duplicates', 'delete', 'groups', 'dt.ceil', 'hour', 'dt.is_leap_year', 'plot.scatter', 'to_native_types', 'is_all_dates', 'is_monotonic', 'plot.hexbin', 'step', 'shift', 'cat.as_unordered', 'stop', 'array', 'lookup', 'shape', 'dt.day', 'cat.rename_categories', 'dt.components', 'swaplevel', 'Period', 'dt.microsecond', 'str.get', 'dt.minute', 'dt.is_quarter_end', 'tz_localize', 'inferred_type', 'argsort', 'read_csv', 'is_', 'dtype', 'asof', 'IntervalArray', 'get_group', 'second', 'dt.microseconds', 'str.zfill', 'first_valid_index', 'set_levels', 'mul', 'groupby', 'le', 'IntervalDtype', 'to_flat_index', 'explode', 'PeriodDtype', 'str.cat', 'unique', 'keys', 'reorder_levels', 'cat.codes', 'read_sql', 'is_populated', 'read_table', 'product', 'str.repeat', 'between_time', 'any', 'to_clipboard', 'slice_indexer', 'dt.freq', 'str.istitle', 'size', 'sparse.from_coo', 'is_integer', 'fold', 'isoformat', 'notna', 'str.rjust', 'str.normalize', 'applymap', 'reorder_categories', 'ExcelWriter', 'dt.daysinmonth', 'columns', 'str.title', 'copy', 'dt.to_pytimedelta', 'toordinal', 'has_duplicates', 'read_gbq', 'argmin', 'slice_locs', 'dt.is_year_start', 'str.findall', 'pivot_table', 'equals', 'str.find', 'str.rindex', 'aggregate', 'IndexSlice', 'to_pickle', 'dt.to_pydatetime', 'reset_index', 'tail', 'to_xarray', 'read_excel', 'nanoseconds', 'str.split', 'from_range', 'utcoffset', 'nsmallest', 'is_boolean', 'skew', 'pad', 'dt.days_in_month', 'to_csv', 'str.upper', 'notnull', 'to_list', 'take', 'count', 'unstack', 'open_left', 'start_time', 'crosstab', 'autocorr', 'view', 'sort_index', 'cat.categories', 'is_non_overlapping_monotonic', 'get_loc', 'period_range', 'kurtosis', 'dayofweek', 'plot.density', 'put', 'corrwith', 'str.count', 'get_level_values', 'is_year_end', 'tshift', 'isnull', 'mean', 'plot.box', '__iter__', 'align', 'read_clipboard', 'names', 'sub', 'value', 'resample', 'days_in_month', 'interval_range', 'union', 'dt.day_name', 'str.len', 'dt.timetz', 'now', 'date_range', 'mid', 'cummin', 'query', 'cumsum', 'from_codes', 'strptime', 'str.get_dummies', 'levels', 'from_frame', 'walk', 'UInt64Dtype', 'tz_convert', 'get', 'str.isspace', 'hist', 'dt.seconds', 'cat.set_categories', 'Interval', 'isna', 'ffill', 'read_stata', 'infer_freq', 'str.isalnum', 'plot.kde', 'rename', 'cat.as_ordered', 'xs', 'rdiv', 'to_latex', 'Int8Dtype', 'timestamp', 'write_file', 'to_perioddelta', 'nanosecond']\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "urls = json.load(open(\"pandas_apis.json\"))\n",
    "data_frame_url = urls[\"df\"]\n",
    "\n",
    "def get_api_list(_url):\n",
    "    page = requests.get(_url)\n",
    "    soup = bs(page.content, 'html.parser')\n",
    "    codes = soup.find_all(\"code\", {\"class\": \"xref py py-obj docutils literal notranslate\"})\n",
    "    apis = []\n",
    "    for code in codes:\n",
    "        api_name = code.find(\"span\").text\n",
    "        if \".\" in api_name:\n",
    "            name = api_name[api_name.index(\".\") + 1:]\n",
    "            apis.append(name)\n",
    "            pass\n",
    "        else:\n",
    "            apis.append(api_name)\n",
    "        pass\n",
    "    return apis\n",
    "\n",
    "data_frame_apis = get_api_list(data_frame_url)\n",
    "# print(data_frame_apis)\n",
    "\n",
    "list_of_apis = []\n",
    "complete_api_sets = []\n",
    "\n",
    "for key in urls:\n",
    "    api_from_url = get_api_list(urls[key])\n",
    "    list_of_apis.append({\n",
    "        \"url_key\": key,\n",
    "        \"url\": urls[key],\n",
    "        \"apis\": api_from_url\n",
    "    })\n",
    "    complete_api_sets.extend(api_from_url)\n",
    "    pass\n",
    "\n",
    "\n",
    "print(\"Dataframe APIs only\")\n",
    "print(data_frame_apis)\n",
    "print(\"=\" * 100)\n",
    "print(\"Pandas APIS\")\n",
    "complete_api_sets = list(set(complete_api_sets))\n",
    "print(complete_api_sets)\n",
    "print(\"=\" * 100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_frame_apis)\n",
    "\n",
    "def dataframe_api_exists(line):\n",
    "    for api in data_frame_apis:\n",
    "        expr = api + \"[ ]*\\(\"\n",
    "#         print(expr)\n",
    "        if len(re.findall(expr, line)) > 0:\n",
    "            return True\n",
    "        pass\n",
    "    return  False\n",
    "\n",
    "\n",
    "# lines = [\"hello()\", \"concat(dsaf)\", \"index()\", \"dasfasd\"]\n",
    "# for l in lines:\n",
    "#     print(l, dataframe_api_exists(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "\n",
      "\n",
      "title :  Remove non-numeric rows in one column with pandas\n",
      "Code From Question : \n",
      "\tCode Snippet 1 : \n",
      "\t\tid, name\n",
      "\t\t1,  A\n",
      "\t\t2,  B\n",
      "\t\t3,  C\n",
      "\t\ttt, D\n",
      "\t\t4,  E\n",
      "\t\t5,  F\n",
      "\t\tde, G\n",
      "\t\t\n",
      "\tData Frame\n",
      "\n",
      "\n",
      "\n",
      "\tCode Snippet 2 : \n",
      "\t\tid, name\n",
      "\t\t1,  A\n",
      "\t\t2,  B\n",
      "\t\t3,  C\n",
      "\t\t4,  E\n",
      "\t\t5,  F\n",
      "\t\t\n",
      "\tData Frame\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Code From Answer : \n",
      "\tCode Snippet 1 : \n",
      "\t\timport pandas as pd\n",
      "\t\tfrom io import StringIO\n",
      "\t\t\n",
      "\t\tdata = \"\"\"\n",
      "\t\tid,name\n",
      "\t\t1,A\n",
      "\t\t2,B\n",
      "\t\t3,C\n",
      "\t\ttt,D\n",
      "\t\t4,E\n",
      "\t\t5,F\n",
      "\t\tde,G\n",
      "\t\t\"\"\"\n",
      "\t\t\n",
      "\t\tdf = pd.read_csv(StringIO(data))\n",
      "\t\t\n",
      "\t\tIn [55]: df\n",
      "\t\tOut[55]: \n",
      "\t\t   id name\n",
      "\t\t0   1    A\n",
      "\t\t1   2    B\n",
      "\t\t2   3    C\n",
      "\t\t3  tt    D\n",
      "\t\t4   4    E\n",
      "\t\t5   5    F\n",
      "\t\t6  de    G\n",
      "\t\t\n",
      "\t\tIn [56]: df[df.id.apply(lambda x: x.isnumeric())]\n",
      "\t\tOut[56]: \n",
      "\t\t  id name\n",
      "\t\t0  1    A\n",
      "\t\t1  2    B\n",
      "\t\t2  3    C\n",
      "\t\t4  4    E\n",
      "\t\t5  5    F\n",
      "\t\t\n",
      "\tData Frame\n",
      "\n",
      "\n",
      "\n",
      "\tCode Snippet 2 : \n",
      "\t\tIn [61]: df[df.id.apply(lambda x: x.isnumeric())].set_index('id')\n",
      "\t\tOut[61]: \n",
      "\t\t   name\n",
      "\t\tid     \n",
      "\t\t1     A\n",
      "\t\t2     B\n",
      "\t\t3     C\n",
      "\t\t4     E\n",
      "\t\t5     F\n",
      "\t\t\n",
      "\tData Frame\n",
      "\n",
      "\n",
      "\n",
      "\tCode Snippet 3 : \n",
      "\t\tdf_big = pd.concat([df]*10000)\n",
      "\t\t\n",
      "\t\tIn [3]: df_big = pd.concat([df]*10000)\n",
      "\t\t\n",
      "\t\tIn [4]: df_big.shape\n",
      "\t\tOut[4]: (70000, 2)\n",
      "\t\t\n",
      "\t\tIn [5]: %timeit df_big[df_big.id.apply(lambda x: x.isnumeric())]\n",
      "\t\t15.3 ms ± 2.02 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\t\t\n",
      "\t\tIn [6]: %timeit df_big[df_big.id.str.isnumeric()]\n",
      "\t\t20.3 ms ± 171 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\t\t\n",
      "\t\tIn [7]: %timeit df_big[pd.to_numeric(df_big['id'], errors='coerce').notnull()]\n",
      "\t\t29.9 ms ± 682 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\t\t\n",
      "\tData Frame\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "title :  Python - How to export monthly data into excel based on month?\n",
      "Code From Question : \n",
      "\tCode Snippet 1 : \n",
      "\t\tDate    Orders\n",
      "\t\t0   2018-01-01  57\n",
      "\t\t1   2018-01-02  324\n",
      "\t\t2   2018-01-03  54\n",
      "\t\t3   2018-01-04  677\n",
      "\t\t4   2018-01-05  234\n",
      "\t\t5   2018-01-06  54\n",
      "\t\t6   2018-01-07  234\n",
      "\t\t7   2018-01-08  65\n",
      "\t\t8   2018-01-09  234\n",
      "\t\t9   2018-01-10  54\n",
      "\t\t10  2018-01-11  234\n",
      "\t\t11  2018-01-12  65\n",
      "\t\t12  2018-01-13  7\n",
      "\t\t13  2018-01-14  6\n",
      "\t\t14  2018-01-15  57\n",
      "\t\t15  2018-01-16  324\n",
      "\t\t16  2018-01-17  54\n",
      "\t\t17  2018-01-18  677\n",
      "\t\t18  2018-01-19  234\n",
      "\t\t19  2018-01-20  54\n",
      "\t\t...\n",
      "\t\t\n",
      "\tData Frame\n",
      "\n",
      "\n",
      "\n",
      "\tCode Snippet 2 : \n",
      "\t\timport pandas as pd\n",
      "\t\tdf = pd.read_excel(\"data/SampleData.xlsx\")\n",
      "\t\tfor dates in Date:\n",
      "\t\t    currMonth = something???\n",
      "\t\t    filename = 'file_'+list(set(pd.to_datetime(df.loc[currMonth, \n",
      "\t\t    'datestart']).dt.strftime('%m%d%y')))[0]+'.xlsx'\n",
      "\t\t    df.loc[idx, 'data'].to_excel(filename)\n",
      "\t\t\n",
      "\tCode\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Code From Answer : \n",
      "\tCode Snippet 1 : \n",
      "\t\tfor month in range(1, 13):\n",
      "\t\t    df_per_month = df[df['Date'].dt.month == month]\n",
      "\t\t    df_per_month.to_excel(f'{month}.xlsx')\n",
      "\t\t\n",
      "\tCode\n",
      "\n",
      "\n",
      "\n",
      "\tCode Snippet 2 : \n",
      "\t\tfor year in range(2018, 2022):\n",
      "\t\t    for month in range(1, 13):\n",
      "\t\t        data = df[(df['Date'].dt.month == month) & (df['Date'].dt.year == year)]\n",
      "\t\t        data.to_excel(f'{month}-{year}.xlsx')\n",
      "\t\t\n",
      "\tCode\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "title :  Erasing outliers from a dataframe in python\n",
      "Code From Question : \n",
      "\tCode Snippet 1 : \n",
      "\t\timport numpy as np\n",
      "\t\timport matplotlib.pyplot as plt\n",
      "\t\tfrom scipy.stats import chi2\n",
      "\t\timport pandas as pd\n",
      "\t\tfrom sklearn.neighbors import NearestNeighbors\n",
      "\t\tfrom sklearn.datasets import make_blobs\n",
      "\t\t\n",
      "\t\t\n",
      "\t\tdf = pd.read_csv(\"data.csv\")\n",
      "\t\t\n",
      "\t\tprint(df.describe())\n",
      "\t\tprint(df.columns)\n",
      "\t\t\n",
      "\t\tdf['height'].plot(kind='hist')\n",
      "\t\tprint(df['height'].value_counts())\n",
      "\t\t\n",
      "\t\tdata= pd.DataFrame(df['height'],df['active'])\n",
      "\t\t\n",
      "\t\tk=1\n",
      "\t\tknn = NearestNeighbors(n_neighbors=k)\n",
      "\t\tknn.fit([df['height']])\n",
      "\t\tneighbors_and_distances = knn.kneighbors([df['height']])\n",
      "\t\tknn_distances = neighbors_and_distances[0]\n",
      "\t\ttnn_distance = np.mean(knn_distances, axis=1)\n",
      "\t\tprint(knn_distances)\n",
      "\t\tPCM = df.plot(kind='scatter', x='x', y='y', c=tnn_distance, colormap='viridis')\n",
      "\t\tplt.show()\n",
      "\t\t\n",
      "\tCode\n",
      "\n",
      "\n",
      "\n",
      "\tCode Snippet 2 : \n",
      "\t\tid,age,gender,height,weight,ap_hi,ap_lo,cholesterol,gluc,smoke,alco,active,cardio\n",
      "\t\t0,18393,2,168,62.0,110,80,1,1,0,0,1,0\n",
      "\t\t1,20228,1,156,85.0,140,90,3,1,0,0,1,1\n",
      "\t\t2,18857,1,50,64.0,130,70,3,1,0,0,0,1\n",
      "\t\t3,17623,2,250,82.0,150,100,1,1,0,0,1,1\n",
      "\t\t\n",
      "\tData Frame\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Code From Answer : \n",
      "\tCode Snippet 1 : \n",
      "\t\tdf = pd.read_csv(\"data.csv\")\n",
      "\t\tX = df[['height', 'weight']]\n",
      "\t\tX.plot(kind='scatter', x='weight', y='height', colormap='viridis')\n",
      "\t\tplt.show()\n",
      "\t\t\n",
      "\tCode\n",
      "\n",
      "\n",
      "\n",
      "\tCode Snippet 2 : \n",
      "\t\tknn = NearestNeighbors(n_neighbors=2).fit(X)\n",
      "\t\tdistances, indices = knn.kneighbors(X)\n",
      "\t\tX['distances'] = distances[:,1]\n",
      "\t\tX.distances\n",
      "\t\t0       1.000000\n",
      "\t\t1       1.000000\n",
      "\t\t2       1.000000\n",
      "\t\t3       3.000000\n",
      "\t\t4       1.000000\n",
      "\t\t5       1.000000\n",
      "\t\t6     133.958949\n",
      "\t\t7     100.344407\n",
      "\t\t       ...\n",
      "\t\t\n",
      "\tData Frame\n",
      "\n",
      "\n",
      "\n",
      "\tCode Snippet 3 : \n",
      "\t\tX.plot(kind='scatter', x='weight', y='height', c='distances', colormap='viridis')\n",
      "\t\tplt.show()\n",
      "\t\t\n",
      "\tCode\n",
      "\n",
      "\n",
      "\n",
      "\tCode Snippet 4 : \n",
      "\t\tMAX_DIST = 10\n",
      "\t\tX[distances < MAX_DIST]\n",
      "\t\t    height  weight\n",
      "\t\t0   162 78.0\n",
      "\t\t1   162 78.0\n",
      "\t\t2   151 76.0\n",
      "\t\t3   151 76.0\n",
      "\t\t4   171 84.0\n",
      "\t\t...\n",
      "\t\t\n",
      "\tData Frame\n",
      "\n",
      "\n",
      "\n",
      "\tCode Snippet 5 : \n",
      "\t\tMAX_DIST = 10\n",
      "\t\tX = X[X.distances < MAX_DIST]\n",
      "\t\t\n",
      "\tCode\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import keyword\n",
    "\n",
    "keywords = keyword.kwlist\n",
    "\n",
    "def keyword_exists(line):\n",
    "    for kw in keywords:\n",
    "        if (kw + \" \") in line or (\" \" + kw) in line:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def min_word_filter(texts, min_word=5):\n",
    "    filtered_texts = []\n",
    "    for t in texts:\n",
    "        if len(t.split()) >= min_word:\n",
    "            filtered_texts.append(t)\n",
    "            pass\n",
    "        pass\n",
    "    return filtered_texts\n",
    "\n",
    "def extract_code(text, filters):\n",
    "    soup = bs(text)\n",
    "    all_code = [code.text for code in soup.find_all('code')]\n",
    "    for f in filters:\n",
    "        all_code = f(all_code)\n",
    "    return all_code\n",
    "    pass\n",
    "\n",
    "def data_frame_exists(code):\n",
    "    lines = [l.strip() for l in code.split(\"\\n\")]\n",
    "    data_frame_re = \"[0-9]+[, \\t]+[.]*\"\n",
    "    matches = []\n",
    "    for l in lines:\n",
    "        if len(re.findall(data_frame_re, l)) > 0 \\\n",
    "            and not keyword_exists(l) \\\n",
    "            and not dataframe_api_exists(l):\n",
    "            matches.append(True)\n",
    "        else:\n",
    "            matches.append(False)\n",
    "    return any(matches)\n",
    "\n",
    "def code_exists(code):\n",
    "    return False\n",
    "\n",
    "def print_formatted_code(cid, code):\n",
    "    print('\\tCode Snippet %d : ' % cid)\n",
    "    lines = code.split('\\n')\n",
    "    lines = ['\\t\\t' + l for l in  lines]\n",
    "    print('\\n'.join(lines))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for a in accepted_answers:\n",
    "    print('=' * 100)\n",
    "    print('\\n')\n",
    "    title = a['title']\n",
    "    code_from_body = extract_code(a['question_body'], filters=[min_word_filter])\n",
    "    code_from_answer = extract_code(a['answer_body'], filters=[min_word_filter])\n",
    "    print(\"title : \", title)\n",
    "    print(\"Code From Question : \")\n",
    "    for cid, c in enumerate(code_from_body):\n",
    "        is_df = data_frame_exists(c)\n",
    "        print_formatted_code(cid+1, c)\n",
    "        print(\"\\t\" + (\"Data Frame\" if is_df else \"Code\")  + \"\\n\\n\\n\")\n",
    "    print('-' * 100)\n",
    "    print(\"Code From Answer : \")\n",
    "    for cid, c in enumerate(code_from_answer):\n",
    "        is_df = data_frame_exists(c)\n",
    "        print_formatted_code(cid+1, c)\n",
    "        print(\"\\t\" + (\"Data Frame\" if is_df else \"Code\") + \"\\n\\n\\n\")\n",
    "    print('-' * 100)\n",
    "    print('\\n')\n",
    "    print('=' * 100)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
