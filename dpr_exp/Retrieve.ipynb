{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c05bc30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pathlib\n",
    "import json\n",
    "import gzip\n",
    "import logging\n",
    "import pickle\n",
    "import time\n",
    "from typing import List, Tuple, Dict, Iterator\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor as T\n",
    "from torch import nn\n",
    "\n",
    "from dpr.data.qa_validation import calculate_matches_by_id\n",
    "from dpr.models import init_biencoder_components\n",
    "from dpr.options import (\n",
    "    add_encoder_params, \n",
    "    setup_args_gpu, \n",
    "    print_args, \n",
    "    set_encoder_params_from_state, \n",
    "    add_tokenizer_params, \n",
    "    add_cuda_params\n",
    ")\n",
    "from dpr.utils.data_utils import Tensorizer\n",
    "from dpr.utils.model_utils import (\n",
    "    setup_for_distributed_mode, \n",
    "    get_model_obj, \n",
    "    load_states_from_checkpoint, \n",
    "    move_to_device\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk \n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "import argparse\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4edd8836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608\n"
     ]
    }
   ],
   "source": [
    "api_lists = json.load(open(\"data/api_list.json\"))\n",
    "\n",
    "def get_test_data(api_lists):\n",
    "    examples = []\n",
    "    fail_count = 0\n",
    "    example_id = 1\n",
    "    for i in range(1, 4):\n",
    "        example_file = f\"../25_K_Examples/part-{i}-output/taken_answers_with_all_details.json\"\n",
    "        data = json.load(open(example_file))\n",
    "        for e in data:\n",
    "            try:\n",
    "                ques_id = e['question_id']\n",
    "                qtitle = e['formatted_input']['question']['title']\n",
    "                qdesc = e['formatted_input']['question']['ques_desc']\n",
    "                codes = e['formatted_input']['answer']['code']\n",
    "                apis = set()\n",
    "                for c in codes:\n",
    "                    tokens = nltk.wordpunct_tokenize(c)\n",
    "                    for tidx, token in enumerate(tokens):\n",
    "                        token = token.strip()\n",
    "                        if tidx >= 0:\n",
    "                            prev_token = tokens[tidx - 1].strip()[-1]\n",
    "                            if (token in api_lists and prev_token == \".\") or token == \"DataFrame\":\n",
    "                                apis.add(token)\n",
    "                api_seq = list(sorted(apis))\n",
    "                if len(api_seq) <= 0:\n",
    "                    continue\n",
    "                examples.append({\n",
    "                    'id': ques_id,\n",
    "                    'query': qtitle.strip().lower() + \" \" + qdesc.strip().lower(),\n",
    "                    \"apis\": api_seq,\n",
    "                    'link': e['link'],\n",
    "                    \"example\": e['formatted_input']\n",
    "                })\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                fail_count += 1\n",
    "    return examples\n",
    "\n",
    "test_examples = get_test_data(list(api_lists.keys()))\n",
    "print(len(test_examples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7cc1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrieverModel:\n",
    "    def __init__(self, model_path, batch_size=64, quiet=False, no_cuda=False):\n",
    "        parser = argparse.ArgumentParser()\n",
    "        add_encoder_params(parser)\n",
    "        add_tokenizer_params(parser)\n",
    "        add_cuda_params(parser)\n",
    "        parser.add_argument(\n",
    "            '--shard_size', \n",
    "            type=int, \n",
    "            default=50000, \n",
    "            help=\"Total amount of data in 1 shard\"\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            '--batch_size', \n",
    "            type=int, \n",
    "            default=32, \n",
    "            help=\"Batch size for the passage encoder forward pass\"\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            '--dataset', \n",
    "            type=str, \n",
    "            default=None, \n",
    "            help=' to build correct dataset parser '\n",
    "        )\n",
    "\n",
    "        self.args = parser.parse_args({})\n",
    "        self.quiet = quiet\n",
    "        self.args.model_file = model_path\n",
    "        setup_args_gpu(self.args)\n",
    "        if no_cuda:\n",
    "            self.args.device = torch.device(\"cpu\")\n",
    "        saved_state = load_states_from_checkpoint(self.args.model_file)\n",
    "        set_encoder_params_from_state(\n",
    "            saved_state.encoder_params, \n",
    "            self.args,\n",
    "            quiet=self.quiet\n",
    "        )\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.tensorizer, self.encoder, _ = init_biencoder_components(\n",
    "            self.args.encoder_model_type, \n",
    "            self.args, \n",
    "            inference_only=True\n",
    "        )\n",
    "        self.encoder.load_state_dict(saved_state.model_dict)\n",
    "        self.query_model = self.encoder.question_model\n",
    "        self.document_model = self.encoder.ctx_model\n",
    "        \n",
    "        self.api_lists = json.load(open(\"data/api_list.json\"))\n",
    "\n",
    "        self.apis = list(sorted(self.api_lists.keys()))\n",
    "        self.api_docs = [self.api_lists[a] for a in self.apis]\n",
    "\n",
    "        _, _, _, self.doc_vectors = self.generate_query_vectors()\n",
    "    \n",
    "    def generate_query_vectors(self):\n",
    "        return self.generate_vectors(\n",
    "            model=self.document_model, \n",
    "            sentences=self.api_docs,\n",
    "            batch_size=self.batch_size,\n",
    "            task='\"API_VECTORS\"'\n",
    "        )\n",
    "    \n",
    "    def generate_vectors(self, model, sentences, batch_size, task):\n",
    "        if not self.quiet:\n",
    "            print(\n",
    "                \"Generating vectors for %d sentences using %s task model\" % (\n",
    "                    len(sentences), \n",
    "                    task\n",
    "                )\n",
    "            )\n",
    "        tensors = []\n",
    "        for ex in sentences:\n",
    "            tensor = self.tensorizer.text_to_tensor(ex)\n",
    "            tensors.append(tensor)\n",
    "        ids = torch.stack(tensors, dim=0)\n",
    "        seg_batch = torch.zeros_like(ids)\n",
    "        attn_mask = self.tensorizer.get_attn_mask(ids)\n",
    "        model.to(self.args.device)\n",
    "        l = ids.size(0)\n",
    "        start_idx = 0\n",
    "        vectors = [] * l\n",
    "        num_batches = math.ceil(l / batch_size)\n",
    "        with torch.no_grad():\n",
    "            batches = range(num_batches) if self.quiet else tqdm(range(num_batches))\n",
    "            for _ in batches:\n",
    "                end_idx = start_idx + batch_size\n",
    "                if end_idx > l:\n",
    "                    end_idx = l\n",
    "                _ids = move_to_device(ids[start_idx:end_idx, :], self.args.device)\n",
    "                _seg_batch = move_to_device(seg_batch[start_idx:end_idx, :], self.args.device)\n",
    "                _attn_mask = move_to_device(attn_mask[start_idx:end_idx, :], self.args.device)\n",
    "                _, _vectors, _ = model(_ids, _seg_batch, _attn_mask)\n",
    "                vectors.append(_vectors)\n",
    "                start_idx = end_idx\n",
    "        vectors = torch.cat(vectors, dim=0)\n",
    "        return ids, seg_batch, attn_mask, vectors\n",
    "    \n",
    "    def retrieve_apis(self, examples, top_k=10):\n",
    "        query_sentences = [ex[\"query\"] for ex in examples]\n",
    "        _, _, _, query_vectors = self.generate_vectors(\n",
    "            model=self.query_model, \n",
    "            sentences=query_sentences, \n",
    "            batch_size=self.batch_size,\n",
    "            task='\"QUESTION_VECTORS\"'\n",
    "        )\n",
    "        similarity_results = cosine_similarity(\n",
    "            query_vectors.cpu().numpy(), \n",
    "            self.doc_vectors.cpu().numpy()\n",
    "        )\n",
    "        singled_out = []\n",
    "        return_examples = []\n",
    "        \n",
    "        torch.save(\n",
    "            (query_sentences, query_vectors.cpu(), self.doc_vectors.cpu(), similarity_results), \n",
    "            \"from_class.pt\"\n",
    "        )\n",
    "        \n",
    "        for exid, ex in enumerate(examples):\n",
    "            example = copy.deepcopy(ex)\n",
    "            pred_similaroty = [(a, s) for a, s in zip(self.apis, similarity_results[exid, :].tolist())]\n",
    "            sorted_apis = sorted(pred_similaroty, key=lambda x: x[1])[::-1]\n",
    "            example[\"expected\"] = example[\"apis\"]\n",
    "            example[\"predicted\"] = sorted_apis\n",
    "            predictions = set([e[0] for e in sorted_apis[:top_k]])\n",
    "            if len(set(example[\"expected\"]).difference(predictions)) == 0:\n",
    "                singled_out.append(example)\n",
    "                pass\n",
    "            return_examples.append(example)\n",
    "            pass\n",
    "        return return_examples, singled_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea7a1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3087d8eda16d49d6b89b05aae65f4464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding args parameter value from checkpoint state. Param = pretrained_model_cfg, value = google/bert_uncased_L-6_H-512_A-8\n",
      "Overriding args parameter value from checkpoint state. Param = encoder_model_type, value = hf_bert\n",
      "Overriding args parameter value from checkpoint state. Param = sequence_length, value = 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vectors for 132 sentences using \"API_VECTORS\" task model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c53953576f04c4da6658b5f8272efc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vectors for 608 sentences using \"QUESTION_VECTORS\" task model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba36391b55ae4e4cab6df2cba8707195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 97\n"
     ]
    }
   ],
   "source": [
    "model_path = \"models/bert/pandas_0/checkpoint_best.pt\"\n",
    "for i in tqdm([1]):\n",
    "    retriever = RetrieverModel(\n",
    "        model_path=f\"models/bert/pandas_{i}/checkpoint_best.pt\", \n",
    "        batch_size=128, \n",
    "        quiet=False,\n",
    "        no_cuda=False\n",
    "    )\n",
    "    _, singles = retriever.retrieve_apis(test_examples)\n",
    "    print(i, len(singles))\n",
    "    del retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e426b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_num(num_str):\n",
    "    if \".\" in num_str:\n",
    "        parts = num_str.split(\".\")\n",
    "        full = parts[0].strip()\n",
    "        frac = parts[1].strip()\n",
    "        if len(frac) < 4:\n",
    "            frac = ('0' * (4-len(frac))) + frac\n",
    "        elif len(frac) > 4:\n",
    "            return None\n",
    "        num_str = full + \".\" + frac\n",
    "    return float(num_str)\n",
    "# print(process_file_num(\"dpr_biencoder.2.108\"[14:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a2cd3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad028c2edf324fed86ffde73d9def2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\t0.0422\t12\tmodels/bert/pandas_5/dpr_biencoder.0.422\n",
      "5\t0.0844\t12\tmodels/bert/pandas_5/dpr_biencoder.0.844\n",
      "5\t0.1266\t21\tmodels/bert/pandas_5/dpr_biencoder.0.1266\n",
      "5\t0.1688\t19\tmodels/bert/pandas_5/dpr_biencoder.0.1688\n",
      "5\t0.211\t17\tmodels/bert/pandas_5/dpr_biencoder.0.2110\n",
      "5\t0.2532\t25\tmodels/bert/pandas_5/dpr_biencoder.0.2532\n",
      "5\t0.2954\t56\tmodels/bert/pandas_5/dpr_biencoder.0.2954\n",
      "5\t0.3376\t37\tmodels/bert/pandas_5/dpr_biencoder.0.3376\n",
      "5\t0.3798\t46\tmodels/bert/pandas_5/dpr_biencoder.0.3798\n",
      "5\t0.422\t79\tmodels/bert/pandas_5/dpr_biencoder.0.4220\n",
      "5\t0.4642\t87\tmodels/bert/pandas_5/dpr_biencoder.0.4642\n",
      "5\t0.5064\t68\tmodels/bert/pandas_5/dpr_biencoder.0.5064\n",
      "5\t0.5067\t68\tmodels/bert/pandas_5/dpr_biencoder.0.5067\n",
      "5\t1.0422\t66\tmodels/bert/pandas_5/dpr_biencoder.1.422\n",
      "5\t1.0844\t68\tmodels/bert/pandas_5/dpr_biencoder.1.844\n",
      "5\t1.1266\t82\tmodels/bert/pandas_5/dpr_biencoder.1.1266\n",
      "5\t1.1688\t68\tmodels/bert/pandas_5/dpr_biencoder.1.1688\n",
      "5\t1.211\t73\tmodels/bert/pandas_5/dpr_biencoder.1.2110\n",
      "5\t1.2532\t77\tmodels/bert/pandas_5/dpr_biencoder.1.2532\n",
      "5\t1.2954\t76\tmodels/bert/pandas_5/dpr_biencoder.1.2954\n",
      "5\t1.3376\t69\tmodels/bert/pandas_5/dpr_biencoder.1.3376\n",
      "5\t1.3798\t75\tmodels/bert/pandas_5/dpr_biencoder.1.3798\n",
      "5\t1.422\t92\tmodels/bert/pandas_5/dpr_biencoder.1.4220\n",
      "5\t1.4642\t90\tmodels/bert/pandas_5/dpr_biencoder.1.4642\n",
      "5\t1.5064\t101\tmodels/bert/pandas_5/dpr_biencoder.1.5064\n",
      "5\t1.5067\t101\tmodels/bert/pandas_5/dpr_biencoder.1.5067\n",
      "5\t2.0422\t89\tmodels/bert/pandas_5/dpr_biencoder.2.422\n",
      "5\t2.0844\t86\tmodels/bert/pandas_5/dpr_biencoder.2.844\n",
      "5\t2.1266\t85\tmodels/bert/pandas_5/dpr_biencoder.2.1266\n",
      "5\t2.1688\t75\tmodels/bert/pandas_5/dpr_biencoder.2.1688\n",
      "5\t2.211\t88\tmodels/bert/pandas_5/dpr_biencoder.2.2110\n",
      "5\t2.2532\t91\tmodels/bert/pandas_5/dpr_biencoder.2.2532\n",
      "5\t2.2954\t87\tmodels/bert/pandas_5/dpr_biencoder.2.2954\n",
      "5\t2.3376\t86\tmodels/bert/pandas_5/dpr_biencoder.2.3376\n",
      "5\t2.3798\t85\tmodels/bert/pandas_5/dpr_biencoder.2.3798\n",
      "5\t2.422\t78\tmodels/bert/pandas_5/dpr_biencoder.2.4220\n",
      "5\t2.4642\t87\tmodels/bert/pandas_5/dpr_biencoder.2.4642\n",
      "5\t2.5064\t99\tmodels/bert/pandas_5/dpr_biencoder.2.5064\n",
      "5\t2.5067\t99\tmodels/bert/pandas_5/dpr_biencoder.2.5067\n",
      "5\t3.0422\t105\tmodels/bert/pandas_5/dpr_biencoder.3.422\n",
      "5\t3.0844\t89\tmodels/bert/pandas_5/dpr_biencoder.3.844\n",
      "5\t3.1266\t95\tmodels/bert/pandas_5/dpr_biencoder.3.1266\n",
      "5\t3.1688\t97\tmodels/bert/pandas_5/dpr_biencoder.3.1688\n",
      "5\t3.211\t94\tmodels/bert/pandas_5/dpr_biencoder.3.2110\n",
      "5\t3.2532\t93\tmodels/bert/pandas_5/dpr_biencoder.3.2532\n",
      "5\t3.2954\t96\tmodels/bert/pandas_5/dpr_biencoder.3.2954\n",
      "5\t3.3376\t97\tmodels/bert/pandas_5/dpr_biencoder.3.3376\n",
      "5\t3.3798\t97\tmodels/bert/pandas_5/dpr_biencoder.3.3798\n",
      "5\t3.422\t109\tmodels/bert/pandas_5/dpr_biencoder.3.4220\n",
      "5\t3.4642\t94\tmodels/bert/pandas_5/dpr_biencoder.3.4642\n",
      "5\t3.5064\t103\tmodels/bert/pandas_5/dpr_biencoder.3.5064\n",
      "5\t3.5067\t103\tmodels/bert/pandas_5/dpr_biencoder.3.5067\n",
      "5\t4.0422\t106\tmodels/bert/pandas_5/dpr_biencoder.4.422\n",
      "5\t4.0844\t93\tmodels/bert/pandas_5/dpr_biencoder.4.844\n",
      "5\t4.1266\t96\tmodels/bert/pandas_5/dpr_biencoder.4.1266\n",
      "5\t4.1688\t88\tmodels/bert/pandas_5/dpr_biencoder.4.1688\n",
      "5\t4.211\t98\tmodels/bert/pandas_5/dpr_biencoder.4.2110\n",
      "5\t4.2532\t101\tmodels/bert/pandas_5/dpr_biencoder.4.2532\n",
      "5\t4.2954\t95\tmodels/bert/pandas_5/dpr_biencoder.4.2954\n",
      "5\t4.3376\t86\tmodels/bert/pandas_5/dpr_biencoder.4.3376\n",
      "5\t4.3798\t86\tmodels/bert/pandas_5/dpr_biencoder.4.3798\n",
      "5\t4.422\t84\tmodels/bert/pandas_5/dpr_biencoder.4.4220\n",
      "5\t4.4642\t93\tmodels/bert/pandas_5/dpr_biencoder.4.4642\n",
      "5\t4.5064\t85\tmodels/bert/pandas_5/dpr_biencoder.4.5064\n",
      "5\t4.5067\t85\tmodels/bert/pandas_5/dpr_biencoder.4.5067\n",
      "5\t5.0422\t98\tmodels/bert/pandas_5/dpr_biencoder.5.422\n",
      "5\t5.0844\t87\tmodels/bert/pandas_5/dpr_biencoder.5.844\n",
      "5\t5.1266\t88\tmodels/bert/pandas_5/dpr_biencoder.5.1266\n",
      "5\t5.1688\t86\tmodels/bert/pandas_5/dpr_biencoder.5.1688\n",
      "5\t5.211\t95\tmodels/bert/pandas_5/dpr_biencoder.5.2110\n",
      "5\t5.2532\t84\tmodels/bert/pandas_5/dpr_biencoder.5.2532\n",
      "5\t5.2954\t83\tmodels/bert/pandas_5/dpr_biencoder.5.2954\n",
      "5\t5.3376\t84\tmodels/bert/pandas_5/dpr_biencoder.5.3376\n",
      "5\t5.3798\t84\tmodels/bert/pandas_5/dpr_biencoder.5.3798\n",
      "5\t5.422\t89\tmodels/bert/pandas_5/dpr_biencoder.5.4220\n",
      "5\t5.4642\t93\tmodels/bert/pandas_5/dpr_biencoder.5.4642\n",
      "5\t5.5064\t93\tmodels/bert/pandas_5/dpr_biencoder.5.5064\n",
      "5\t5.5067\t93\tmodels/bert/pandas_5/dpr_biencoder.5.5067\n",
      "5\t6.0422\t92\tmodels/bert/pandas_5/dpr_biencoder.6.422\n",
      "5\t6.0844\t85\tmodels/bert/pandas_5/dpr_biencoder.6.844\n",
      "5\t6.1266\t92\tmodels/bert/pandas_5/dpr_biencoder.6.1266\n",
      "5\t6.1688\t80\tmodels/bert/pandas_5/dpr_biencoder.6.1688\n",
      "5\t6.211\t84\tmodels/bert/pandas_5/dpr_biencoder.6.2110\n",
      "5\t6.2532\t90\tmodels/bert/pandas_5/dpr_biencoder.6.2532\n",
      "5\t6.2954\t91\tmodels/bert/pandas_5/dpr_biencoder.6.2954\n",
      "5\t6.3376\t95\tmodels/bert/pandas_5/dpr_biencoder.6.3376\n",
      "5\t6.3798\t97\tmodels/bert/pandas_5/dpr_biencoder.6.3798\n",
      "5\t6.422\t95\tmodels/bert/pandas_5/dpr_biencoder.6.4220\n",
      "5\t6.4642\t95\tmodels/bert/pandas_5/dpr_biencoder.6.4642\n",
      "5\t6.5064\t84\tmodels/bert/pandas_5/dpr_biencoder.6.5064\n",
      "5\t6.5067\t84\tmodels/bert/pandas_5/dpr_biencoder.6.5067\n",
      "5\t7.0422\t87\tmodels/bert/pandas_5/dpr_biencoder.7.422\n",
      "5\t7.0844\t85\tmodels/bert/pandas_5/dpr_biencoder.7.844\n",
      "5\t7.1266\t89\tmodels/bert/pandas_5/dpr_biencoder.7.1266\n",
      "5\t7.1688\t86\tmodels/bert/pandas_5/dpr_biencoder.7.1688\n",
      "5\t7.211\t85\tmodels/bert/pandas_5/dpr_biencoder.7.2110\n",
      "5\t7.2532\t90\tmodels/bert/pandas_5/dpr_biencoder.7.2532\n",
      "5\t7.2954\t94\tmodels/bert/pandas_5/dpr_biencoder.7.2954\n",
      "5\t7.3376\t83\tmodels/bert/pandas_5/dpr_biencoder.7.3376\n",
      "5\t7.3798\t84\tmodels/bert/pandas_5/dpr_biencoder.7.3798\n",
      "5\t7.422\t87\tmodels/bert/pandas_5/dpr_biencoder.7.4220\n",
      "5\t7.4642\t90\tmodels/bert/pandas_5/dpr_biencoder.7.4642\n",
      "5\t7.5064\t88\tmodels/bert/pandas_5/dpr_biencoder.7.5064\n",
      "5\t7.5067\t88\tmodels/bert/pandas_5/dpr_biencoder.7.5067\n",
      "5\t8.0422\t89\tmodels/bert/pandas_5/dpr_biencoder.8.422\n",
      "5\t8.0844\t86\tmodels/bert/pandas_5/dpr_biencoder.8.844\n",
      "5\t8.1266\t88\tmodels/bert/pandas_5/dpr_biencoder.8.1266\n",
      "5\t8.1688\t91\tmodels/bert/pandas_5/dpr_biencoder.8.1688\n",
      "5\t8.211\t93\tmodels/bert/pandas_5/dpr_biencoder.8.2110\n",
      "5\t8.2532\t91\tmodels/bert/pandas_5/dpr_biencoder.8.2532\n",
      "5\t8.2954\t91\tmodels/bert/pandas_5/dpr_biencoder.8.2954\n",
      "5\t8.3376\t88\tmodels/bert/pandas_5/dpr_biencoder.8.3376\n",
      "5\t8.3798\t89\tmodels/bert/pandas_5/dpr_biencoder.8.3798\n",
      "5\t8.422\t87\tmodels/bert/pandas_5/dpr_biencoder.8.4220\n",
      "5\t8.4642\t93\tmodels/bert/pandas_5/dpr_biencoder.8.4642\n",
      "5\t8.5064\t90\tmodels/bert/pandas_5/dpr_biencoder.8.5064\n",
      "5\t8.5067\t90\tmodels/bert/pandas_5/dpr_biencoder.8.5067\n",
      "5\t9.0422\t90\tmodels/bert/pandas_5/dpr_biencoder.9.422\n",
      "5\t9.0844\t89\tmodels/bert/pandas_5/dpr_biencoder.9.844\n",
      "5\t9.1266\t92\tmodels/bert/pandas_5/dpr_biencoder.9.1266\n",
      "5\t9.1688\t88\tmodels/bert/pandas_5/dpr_biencoder.9.1688\n",
      "5\t9.211\t91\tmodels/bert/pandas_5/dpr_biencoder.9.2110\n",
      "5\t9.2532\t86\tmodels/bert/pandas_5/dpr_biencoder.9.2532\n",
      "5\t9.2954\t90\tmodels/bert/pandas_5/dpr_biencoder.9.2954\n",
      "5\t9.3376\t93\tmodels/bert/pandas_5/dpr_biencoder.9.3376\n",
      "5\t9.3798\t92\tmodels/bert/pandas_5/dpr_biencoder.9.3798\n",
      "5\t9.422\t90\tmodels/bert/pandas_5/dpr_biencoder.9.4220\n",
      "5\t9.4642\t87\tmodels/bert/pandas_5/dpr_biencoder.9.4642\n",
      "5\t9.5064\t87\tmodels/bert/pandas_5/dpr_biencoder.9.5064\n",
      "5\t9.5067\t87\tmodels/bert/pandas_5/dpr_biencoder.9.5067\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "directories = [5]\n",
    "all_results = {}\n",
    "\n",
    "\n",
    "output_file = open(\"all_outputs.tsv\", 'a')\n",
    "\n",
    "for d in directories:\n",
    "    results = {}\n",
    "    files = os.listdir(os.path.join(\"models/bert\", \"pandas_\" + str(d)))\n",
    "    taken_files = [f for f in files if f.startswith(\"dpr_biencoder\")]\n",
    "    points = []\n",
    "    for f in taken_files:\n",
    "        v = process_file_num(f[14:])\n",
    "        if v is not None:\n",
    "            points.append((f, v))\n",
    "    points = sorted(points, key=lambda x: x[1])\n",
    "    for i, (f, e) in enumerate(tqdm(points, total=len(points))):\n",
    "        model_path = os.path.join(\"models/bert/\", \"pandas_\" + str(d), f)\n",
    "        retriever = RetrieverModel(\n",
    "            model_path=model_path, \n",
    "            batch_size=128, \n",
    "            quiet=True\n",
    "        )\n",
    "        _, singles = retriever.retrieve_apis(test_examples)\n",
    "        results[f] = len(singles)\n",
    "        print(\n",
    "            d, e, len(singles), os.path.join(\"models/bert/\", \"pandas_\" + str(d), f), \n",
    "            sep=\"\\t\", \n",
    "            file=output_file, \n",
    "            flush=True\n",
    "        )\n",
    "        if i % 1 == 0:\n",
    "            print(\n",
    "                d, e, len(singles), os.path.join(\"models/bert/\", \"pandas_\" + str(d), f), \n",
    "                sep=\"\\t\", \n",
    "            )\n",
    "        pass\n",
    "        del retriever\n",
    "    print(\"=\" * 100)\n",
    "    all_results[d] = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c5efd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef63e1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding args parameter value from checkpoint state. Param = pretrained_model_cfg, value = google/bert_uncased_L-6_H-512_A-8\n",
      "Overriding args parameter value from checkpoint state. Param = encoder_model_type, value = hf_bert\n",
      "Overriding args parameter value from checkpoint state. Param = sequence_length, value = 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vectors for 132 sentences using \"API_VECTORS\" task model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02d1bd269de4b6f8c588e0cdc345bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vectors for 608 sentences using \"QUESTION_VECTORS\" task model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49c2d12c5c04eeebe87b9d28c7e0ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding args parameter value from checkpoint state. Param = pretrained_model_cfg, value = google/bert_uncased_L-6_H-512_A-8\n",
      "Overriding args parameter value from checkpoint state. Param = encoder_model_type, value = hf_bert\n",
      "Overriding args parameter value from checkpoint state. Param = sequence_length, value = 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 74\n",
      "Generating vectors for 132 sentences using \"API_VECTORS\" task model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e406f0e3073545e38b52b51d0afa3d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vectors for 608 sentences using \"QUESTION_VECTORS\" task model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf8cbabd609459bab2c30f2f6ab3a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding args parameter value from checkpoint state. Param = pretrained_model_cfg, value = google/bert_uncased_L-6_H-512_A-8\n",
      "Overriding args parameter value from checkpoint state. Param = encoder_model_type, value = hf_bert\n",
      "Overriding args parameter value from checkpoint state. Param = sequence_length, value = 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 97\n",
      "Generating vectors for 132 sentences using \"API_VECTORS\" task model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0927d53a8ff487f939baca529d34492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vectors for 608 sentences using \"QUESTION_VECTORS\" task model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dface3b6e6d4922a7cca3568a88a5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding args parameter value from checkpoint state. Param = pretrained_model_cfg, value = google/bert_uncased_L-6_H-512_A-8\n",
      "Overriding args parameter value from checkpoint state. Param = encoder_model_type, value = hf_bert\n",
      "Overriding args parameter value from checkpoint state. Param = sequence_length, value = 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vectors for 132 sentences using \"API_VECTORS\" task model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9827620fbafb42ed88c39982bdd467cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vectors for 608 sentences using \"QUESTION_VECTORS\" task model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237696bd964d4ca4974d11cbd7b5b6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 87\n"
     ]
    }
   ],
   "source": [
    "for p in [0, 1, 2, 5]:\n",
    "    retriever = RetrieverModel(\n",
    "        model_path=f\"models/bert/pandas_{p}/checkpoint_best.pt\", \n",
    "        batch_size=128, \n",
    "        quiet=False\n",
    "    )\n",
    "    _, singles = retriever.retrieve_apis(test_examples, top_k=10)\n",
    "    print(p, len(singles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0ed827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
